import requests
import pandas as pd
from datetime import datetime, timedelta, timezone
import os
import pytz
import psycopg2
from psycopg2 import sql

# API and Access Token URLs
API_URL = ""
ACCESS_TOKEN_URL = ""

def get_access_token():
    response = requests.post(ACCESS_TOKEN_URL)
    response_data = response.json()
    if "access_token" in response_data:
        print("Access Token generated successfully.")
        return response_data["access_token"]
    raise Exception("Failed to generate access token")

def fetch_data(start_date, end_date, auth_token):
    headers = {"Authorization": f"Bearer {auth_token}", "Content-Type": "application/json"}
    all_data = []
    top = 10000
    skip = 0
    while True:
        params = {"startdate": start_date, "enddate": end_date, "top": top, "skip": skip}
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()
        if "completedContacts" in data and data["completedContacts"]:
            all_data.extend(data["completedContacts"])
            skip += top
            if len(data["completedContacts"]) < top:
                break
        else:
            break
    print(f"Total records fetched: {len(all_data)}")
    return all_data

def save_raw_data_to_csv(df, dir_path):
    file_path = os.path.join(dir_path, "Raw_data.csv")
    df.to_csv(file_path, index=False)
    print(f"Raw data saved to '{file_path}' successfully!")
    return file_path

def clean_csv(csv_file_path):
    df = pd.read_csv(csv_file_path)
    
    # Drop the "tags" column if it exists.
    if "tags" in df.columns:
        df.drop(columns=["tags"], inplace=True)
        print("Dropped 'tags' column from CSV.")
    
    # List of datetime columns to clean and convert to EST.
    datetime_columns = [
        "contactStartDate", 
        "dateACWWarehoused", 
        "dateContactWarehoused", 
        "lastUpdateTime"
    ]
    for col in datetime_columns:
        if col in df.columns:
            # Remove literal "T" and "Z"
            df[col] = df[col].astype(str).str.replace("T", " ").str.replace("Z", "", regex=False)
            # Convert string to datetime using the format "YYYY-MM-DD HH:MM:SS"
            df[col] = pd.to_datetime(df[col], format="%Y-%m-%d %H:%M:%S", errors="coerce")
            # Localize as UTC then convert to EST.
            df[col] = df[col].dt.tz_localize("UTC").dt.tz_convert("US/Eastern")
    df.to_csv(csv_file_path, index=False)
    print(f"CSV file cleaned and updated at '{csv_file_path}'")
    return df

def create_table_and_insert_data(db_conn, table_name, df):
    cursor = db_conn.cursor()
    columns = df.columns
    column_types = []
    
    # Define the list of datetime columns (to be stored as TIMESTAMP)
    datetime_columns = [
        "contactStartDate", 
        "dateACWWarehoused", 
        "dateContactWarehoused", 
        "lastUpdateTime"
    ]
    for col in columns:
        if col in datetime_columns:
            column_types.append(f"{col} TIMESTAMP")
        else:
            column_types.append(f"{col} TEXT")
    
    # Create table if it does not already exist.
    create_table_query = sql.SQL("CREATE TABLE IF NOT EXISTS {} ({})").format(
        sql.Identifier(table_name),
        sql.SQL(", ").join(sql.SQL(item) for item in column_types)
    )
    cursor.execute(create_table_query)
    
    # Insert data into the table.
    for row in df.itertuples(index=False, name=None):
        insert_query = sql.SQL("INSERT INTO {} ({}) VALUES ({})").format(
            sql.Identifier(table_name),
            sql.SQL(", ").join(sql.Identifier(col) for col in columns),
            sql.SQL(", ").join(sql.Placeholder() * len(columns))
        )
        cursor.execute(insert_query, row)
    
    db_conn.commit()
    cursor.close()
    print(f"Data inserted into table '{table_name}' successfully!")

def delete_csv(file_path):
    os.remove(file_path)
    print(f"CSV file '{file_path}' deleted successfully!")

if __name__ == "__main__":
    # Create a Temp directory in the current working directory.
    base_dir = os.getcwd()
    temp_dir = os.path.join(base_dir, "Temp")
    if not os.path.exists(temp_dir):
        os.makedirs(temp_dir)
        print(f"Directory created: {temp_dir}")
    else:
        print(f"Directory exists: {temp_dir}")
    
    # Set time range in UTC for the last 1 hour.
    end_date = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')
    start_date = (datetime.now(timezone.utc) - timedelta(hours=1)).strftime('%Y-%m-%dT%H:%M:%SZ')
    
    # Get the access token and fetch the data from the API.
    auth_token = get_access_token()
    data = fetch_data(start_date, end_date, auth_token)
    
    if data:
        # Convert the fetched data into a DataFrame.
        df = pd.DataFrame(data)
        # Save the raw data to CSV.
        csv_file_path = save_raw_data_to_csv(df, temp_dir)
        # Clean the CSV: remove "T" and "Z", convert datetime columns to EST, drop "tags" column.
        df_clean = clean_csv(csv_file_path)
        
        # Connect to PostgreSQL (adjust connection parameters as needed).
        db_conn = psycopg2.connect(
            dbname="postgres", 
            user="postgres", 
            password="automation@123", 
            host="", 
            port=5432
        )
        # Insert data from the cleaned CSV into the database.
        create_table_and_insert_data(db_conn, "raw_contact_data_test", df_clean)
        
        # Delete the CSV file after processing.
        delete_csv(csv_file_path)
        db_conn.close()
    else:
        print("No data fetched for the given time range.")
