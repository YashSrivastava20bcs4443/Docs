import requests
import psycopg2
import json
from datetime import datetime, timedelta

# PostgreSQL connection details
DB_CONFIG = {
    "host": "172.16.130.247",
    "database": "your_database_name",
    "user": "postgres",
    "password": "Zxcv@1234"
}

# API and Access Token Details
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"

# Generate Access Token
def get_access_token():
    response = requests.post(ACCESS_TOKEN_URL)
    response.raise_for_status()
    return response.json().get('access_token')

# Ensure necessary columns and create raw table if not exist
def setup_database():
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()

    cursor.execute("""
    CREATE TABLE IF NOT EXISTS raw_completed_contacts (
        id SERIAL PRIMARY KEY,
        raw_data JSONB,
        inserted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );

    CREATE TABLE IF NOT EXISTS completed_contacts (
        contact_id BIGINT,
        master_contact_id BIGINT,
        contact_start_date TIMESTAMP,
        last_update_time TIMESTAMP,
        from_addr VARCHAR(100),
        to_addr VARCHAR(100),
        media_type INT,
        is_outbound BOOLEAN,
        abandoned BOOLEAN,
        agent_seconds INT,
        in_queue INT,
        pre_queue_seconds INT,
        end_reason VARCHAR(50)
    );
    """)
    conn.commit()
    conn.close()

# Fetch Data from API
def fetch_data(start_date, end_date, auth_token):
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json"
    }
    params = {
        "startdate": start_date,
        "enddate": end_date,
        "top": 10000,
        "skip": 0
    }

    all_data = []
    while True:
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()
        if "completedContacts" in data and data["completedContacts"]:
            all_data.extend(data["completedContacts"])
            params["skip"] += 10000
        else:
            break
    print(f"Total records fetched: {len(all_data)}")
    return all_data

# Store Raw Data to PostgreSQL
def store_raw_data(data):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    cursor.execute("INSERT INTO raw_completed_contacts (raw_data) VALUES (%s)", (json.dumps(data),))
    conn.commit()
    conn.close()

# Filter Data Based on Requirements
def filter_data(data):
    filtered_data = []
    for contact in data:
        media_type = contact.get('mediaType')
        is_outbound = contact.get('isOutbound')
        abandoned = contact.get('abandoned')
        agent_seconds = int(contact.get('agentSeconds', 0))
        in_queue = int(contact.get('inQueue', 0))
        pre_queue_seconds = int(contact.get('preQueueSeconds', 0))
        end_reason = contact.get('endReason')

        # IVR Abandon Count
        if media_type == 4 and not is_outbound and not abandoned and agent_seconds == 0 and in_queue == 0 and pre_queue_seconds > 1:
            filtered_data.append(contact)

        # Polite Disconnect Count
        elif media_type == 4 and not is_outbound and not abandoned and agent_seconds == 0 and in_queue == 0 and pre_queue_seconds > 1 and end_reason == "Contact Hang Up via Script":
            filtered_data.append(contact)

        # Queue Abandon Count
        elif media_type == 4 and is_outbound and not abandoned and agent_seconds == 0 and in_queue > 0 and pre_queue_seconds > 0:
            filtered_data.append(contact)
    
    return filtered_data

# Store Filtered Data to PostgreSQL
def store_filtered_data(data):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    for contact in data:
        cursor.execute("""
            INSERT INTO completed_contacts (
                contact_id, master_contact_id, contact_start_date, last_update_time, 
                from_addr, to_addr, media_type, is_outbound, abandoned, 
                agent_seconds, in_queue, pre_queue_seconds, end_reason
            )
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            contact.get('contactId'),
            contact.get('masterContactId'),
            contact.get('contactStartDate'),
            contact.get('lastUpdateTime'),
            contact.get('fromAddr'),
            contact.get('toAddr'),
            contact.get('mediaType'),
            contact.get('isOutbound'),
            contact.get('abandoned'),
            contact.get('agentSeconds'),
            contact.get('inQueue'),
            contact.get('preQueueSeconds'),
            contact.get('endReason')
        ))
    conn.commit()
    conn.close()
    print("Filtered data stored successfully.")

# Main Execution
if __name__ == "__main__":
    setup_database()
    token = get_access_token()
    end_date = datetime.utcnow()
    start_date = end_date - timedelta(hours=2)
    start_date_str = start_date.strftime("%Y-%m-%dT%H:%M:%SZ")
    end_date_str = end_date.strftime("%Y-%m-%dT%H:%M:%SZ")

    # Fetch and Store Raw Data
    data = fetch_data(start_date_str, end_date_str, token)
    if data:
        store_raw_data(data)

        # Filter Data and Store Filtered Data
        filtered_data = filter_data(data)
        if filtered_data:
            store_filtered_data(filtered_data)
        else:
            print("No records matched the filtering criteria.")
    else:
        print("No data fetched from API.")
