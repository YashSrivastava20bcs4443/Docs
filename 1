import requests
import json
import csv
import psycopg2
from datetime import datetime, timedelta, timezone

# API and Access Token Details
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"
DB_CONFIG = {
    "host": "172.16.130.247",
    "database": "postgres",
    "user": "postgres",
    "password": "Zxcv@1234"
}

# Generate Access Token
def get_access_token():
    response = requests.post(ACCESS_TOKEN_URL)
    response_data = response.json()
    return response_data.get('access_token')

# Fetch data from API
def fetch_data():
    access_token = get_access_token()
    headers = {
        'Authorization': f'Bearer {access_token}'
    }
    end_time = datetime.now(timezone.utc)
    start_time = end_time - timedelta(hours=2)
    params = {
        "startDate": start_time.isoformat(),
        "endDate": end_time.isoformat(),
        "mediaTypeId": 4
    }
    response = requests.get(API_URL, headers=headers, params=params)
    return response.json().get("completedContacts", [])

# Save data to CSV
def save_data_to_csv(data):
    csv_file = "completed_contacts.csv"
    with open(csv_file, mode='w', newline='') as file:
        writer = csv.DictWriter(file, fieldnames=data[0].keys())
        writer.writeheader()
        writer.writerows(data)
    return csv_file

# Create database table if not exists
def create_table_if_not_exists():
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    cursor.execute('''CREATE TABLE IF NOT EXISTS completed_contacts (
                        contactId BIGINT PRIMARY KEY,
                        masterContactId BIGINT,
                        mediaTypeId INTEGER,
                        isOutbound BOOLEAN,
                        abandoned BOOLEAN,
                        agentSeconds INTEGER,
                        inQueueSeconds INTEGER,
                        preQueueSeconds INTEGER,
                        endReason TEXT,
                        toAddr TEXT
                    )''')
    conn.commit()
    conn.close()

# Store data into PostgreSQL
def store_data_to_postgresql(data):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    for record in data:
        try:
            cursor.execute('''INSERT INTO completed_contacts (
                            contactId, masterContactId, mediaTypeId, isOutbound, abandoned, 
                            agentSeconds, inQueueSeconds, preQueueSeconds, endReason, toAddr)
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                            ON CONFLICT (contactId) DO NOTHING''',
                            (record['contactId'], record['masterContactId'], record['mediaTypeId'],
                             record['isOutbound'], record['abandoned'], record['agentSeconds'],
                             record['inQueueSeconds'], record['preQueueSeconds'],
                             record['endReason'], record['toAddr']))
        except psycopg2.DataError:
            print("Data error encountered. Check for integer overflow.")
    conn.commit()
    conn.close()

# Filter and summarize data
def filter_data(data):
    filtered_data = [d for d in data if d.get('mediaTypeId') == 4 and not d.get('isOutbound') and d.get('masterContactId') == d.get('contactId')]
    return filtered_data

# Main workflow
data = fetch_data()
create_table_if_not_exists()
csv_file = save_data_to_csv(data)
filtered_data = filter_data(data)
store_data_to_postgresql(filtered_data)
print("Data pipeline completed successfully.")
