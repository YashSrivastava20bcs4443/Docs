import requests
import psycopg2
import pandas as pd
from datetime import datetime, timedelta, timezone
import os

# PostgreSQL connection details
DB_CONFIG = {
    "host": "172.16.130.247",
    "database": "postgres",
    "user": "postgres",
    "password": "Zxcv@1234"
}

# API and Access Token Details
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"

# Function to generate access token
def get_access_token():
    try:
        response = requests.post(ACCESS_TOKEN_URL)
        response_data = response.json()
        if "access_token" in response_data:
            print("Access Token generated successfully.")
            return response_data['access_token']
        else:
            raise Exception("Failed to generate access token.")
    except Exception as e:
        print(f"Error generating access token: {e}")
        exit()

# Function to fetch data from the API
def fetch_data(start_date, end_date, auth_token):
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json"
    }
    all_data = []
    skip = 0
    top = 10000
    while True:
        params = {"startdate": start_date, "enddate": end_date, "top": top, "skip": skip}
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()
        if "completedContacts" in data and data["completedContacts"]:
            all_data.extend(data["completedContacts"])
            skip += top
            if len(data["completedContacts"]) < top:
                break
        else:
            break
    print(f"Total records fetched: {len(all_data)}")
    return all_data

# Flatten nested data
def flatten_data(data):
    flattened = []
    for record in data:
        flat_record = {}
        for key, value in record.items():
            if isinstance(value, dict):
                for sub_key, sub_value in value.items():
                    flat_record[f"{key}_{sub_key}"] = sub_value
            else:
                flat_record[key] = value
        flattened.append(flat_record)
    return flattened

# Save data to CSV
def save_data_to_csv(data):
    try:
        df = pd.DataFrame(data)
        csv_file = "new_completed_contacts1.csv"
        df.to_csv(csv_file, index=False)
        print(f"Data saved to {csv_file}")
        return csv_file
    except Exception as e:
        print(f"Error saving data to CSV: {e}")

# Ensure the required table exists
def create_table_if_not_exists(table_name):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    create_table_query = f"""
    CREATE TABLE IF NOT EXISTS {table_name} (
        contact_id VARCHAR(50),
        start_date TIMESTAMP,
        end_date TIMESTAMP,
        from_addr VARCHAR(100),
        to_addr VARCHAR(100),
        media_type_id VARCHAR(50),
        is_outbound BOOLEAN,
        master_contact_id VARCHAR(50)
    );
    """
    cursor.execute(create_table_query)
    conn.commit()
    cursor.close()
    conn.close()

# Store data into PostgreSQL
def store_data_to_postgresql(data, table_name):
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        create_table_if_not_exists(table_name)
        for _, contact in data.iterrows():
            cursor.execute(f"""
            INSERT INTO {table_name} (contact_id, start_date, end_date, from_addr, to_addr, media_type_id, is_outbound, master_contact_id)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """,
            (contact.get('contactId'),
             contact.get('contactStartDate'),
             contact.get('lastUpdateTime'),
             contact.get('fromAddress'),
             contact.get('toAddress'),
             contact.get('mediaTypeId'),
             contact.get('isOutbound'),
             contact.get('masterContactId')))
        conn.commit()
        cursor.close()
        conn.close()
        print(f"Data successfully stored in table: {table_name}")
    except Exception as e:
        print(f"Error storing data to PostgreSQL: {e}")

# Data Aggregation and Summary Table
def generate_summary(data):
    df = pd.DataFrame(data)
    df['toAddress'] = df['toAddress'].astype(str)
    summary = df.groupby('toAddress').agg(
        Offered_Calls=('contactId', 'count'),
        Answered=('agentSeconds', lambda x: (x > 0).sum()),
        IVR_Abandon=('preQueueSeconds', lambda x: ((x > 1) & (df['inQueueSeconds'] == 0) & (df['agentSeconds'] == 0)).sum()),
        Queue_Abandon=('inQueueSeconds', lambda x: ((x > 0) & (df['agentSeconds'] == 0)).sum()),
        Polite_Disconnect=('endReason', lambda x: ((x == "Contact Hung Up") | (x == "Contact Hang Up via Script")).sum())
    ).reset_index()
    print("Summary table generated:")
    print(summary)
    return summary

# Ensure the summary table exists
def create_summary_table_if_not_exists():
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    create_table_query = """
    CREATE TABLE IF NOT EXISTS call_summary (
        toAddress VARCHAR(100),
        Offered_Calls INTEGER,
        Answered INTEGER,
        IVR_Abandon INTEGER,
        Queue_Abandon INTEGER,
        Polite_Disconnect INTEGER
    );
    """
    cursor.execute(create_table_query)
    conn.commit()
    cursor.close()
    conn.close()

# Store the summary data in PostgreSQL
def store_summary_to_postgresql(summary):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    create_summary_table_if_not_exists()
    for _, row in summary.iterrows():
        cursor.execute(
            """
            INSERT INTO call_summary (toAddress, Offered_Calls, Answered, IVR_Abandon, Queue_Abandon, Polite_Disconnect)
            VALUES (%s, %s, %s, %s, %s, %s)
            """,
            (row['toAddress'], row['Offered_Calls'], row['Answered'], row['IVR_Abandon'], row['Queue_Abandon'], row['Polite_Disconnect'])
        )
    conn.commit()
    cursor.close()
    conn.close()

# Main Execution Flow
if __name__ == "__main__":
    auth_token = get_access_token()
    end_date = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')
    start_date = (datetime.now(timezone.utc) - timedelta(hours=2)).strftime('%Y-%m-%dT%H:%M:%SZ')

    data = fetch_data(start_date, end_date, auth_token)
    if data:
        flattened_data = flatten_data(data)
        save_data_to_csv(flattened_data)
        df = pd.DataFrame(flattened_data)

        store_data_to_postgresql(df, 'raw')

        summary_data = generate_summary(flattened_data)
        if not summary_data.empty:
            store_summary_to_postgresql(summary_data)
        else:
            print("No summary data to store.")
    else:
        print("No data fetched for the given time range.")

