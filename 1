import requests
import pandas as pd
import psycopg2
from psycopg2 import sql

# Database connection details
DB_CONFIG = {
    'dbname': 'your_dbname',
    'user': 'postgres',
    'password': 'Zxcv@1234',
    'host': '172.16.130.247',
    'port': '5432'
}

# Step 1: Fetch Data from API and Save to CSV
def fetch_data_and_save_to_csv():
    url = "https://api.example.com/data"
    headers = {"Authorization": "Bearer YOUR_ACCESS_TOKEN"}
    response = requests.get(url, headers=headers)
    data = response.json()

    df = pd.DataFrame(data)
    df.to_csv('completed_contacts.csv', index=False)
    print("Data saved to completed_contacts.csv")
    return df

# Step 2: Insert Raw CSV Data into Database Table
def insert_raw_data_to_db():
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()

    # Ensure table exists
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS completed_contacts (
        contact_id VARCHAR,
        contact_start_date TIMESTAMP,
        last_update_time TIMESTAMP,
        from_address VARCHAR,
        to_address VARCHAR,
        mediaType VARCHAR,
        isOutbound BOOLEAN,
        masterContactId VARCHAR
    );
    ''')
    conn.commit()

    df = pd.read_csv('completed_contacts.csv')

    # Column name correction
    df.columns = df.columns.str.strip()

    for _, row in df.iterrows():
        try:
            cursor.execute(
                """
                INSERT INTO completed_contacts (contact_id, contact_start_date, last_update_time, from_address, to_address, mediaType, isOutbound, masterContactId)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                """,
                (row['contactId'], row['contactStartDate'], row['lastupdateTime'], row['FromAddress'], row['toAddress'], row['mediaType'], row['isOutbound'], row['masterContactId'])
            )
        except Exception as e:
            print(f"Error inserting row: {e}")

    conn.commit()
    cursor.close()
    conn.close()
    print("Raw data inserted into completed_contacts table")

# Step 3: Filter and Summarize the Data
def filter_and_summarize_data():
    df = pd.read_csv('completed_contacts.csv')

    # Column correction for consistent naming
    df.columns = df.columns.str.strip()

    summary = {
        'unique_toll_numbers': df['toAddress'].nunique(),
        'ivr_offered_count': df[df['mediaType'] == 'IVR'].shape[0],
        'ivr_abandon_count': df[df['abandoned'] == True].shape[0],
        'polite_disconnect_count': df[df['endReason'] == 'PoliteDisconnect'].shape[0],
        'queue_abandon_count': df[df['endReason'] == 'QueueAbandon'].shape[0]
    }
    print("Summary Data:", summary)
    return summary

# Step 4: Save Filtered Summary Data in Another Database Table
def save_summary_to_db(summary):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()

    cursor.execute('''
    CREATE TABLE IF NOT EXISTS dashboard_summary (
        media_type VARCHAR,
        unique_toll_numbers INT,
        ivr_offered_count INT,
        ivr_abandon_count INT,
        polite_disconnect_count INT,
        queue_abandon_count INT
    );
    ''')

    try:
        cursor.execute(
            """
            INSERT INTO dashboard_summary (media_type, unique_toll_numbers, ivr_offered_count, ivr_abandon_count, polite_disconnect_count, queue_abandon_count)
            VALUES (%s, %s, %s, %s, %s, %s)
            """,
            ('IVR', summary['unique_toll_numbers'], summary['ivr_offered_count'], summary['ivr_abandon_count'], summary['polite_disconnect_count'], summary['queue_abandon_count'])
        )
    except Exception as e:
        print(f"Error storing summary data: {e}")

    conn.commit()
    cursor.close()
    conn.close()
    print("Summary data stored successfully")

# Main execution flow
if __name__ == "__main__":
    try:
        fetch_data_and_save_to_csv()
        insert_raw_data_to_db()
        summary_data = filter_and_summarize_data()
        save_summary_to_db(summary_data)
    except Exception as e:
        print(f"Error in script execution: {e}")
