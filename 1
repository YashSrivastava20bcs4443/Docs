
import requests
import psycopg2
import pandas as pd
from datetime import datetime, timedelta, timezone
import os

# PostgreSQL connection details
DB_CONFIG = {
    "host": "172.16.130.247",
    "database": "postgres",
    "user": "postgres",
    "password": "Zxcv@1234"
}

# API and Access Token Details
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"

# Function to generate access token
def get_access_token():
    try:
        response = requests.post(ACCESS_TOKEN_URL)
        response_data = response.json()
        if "access_token" in response_data:
            print("Access Token generated successfully.")
            return response_data['access_token']
        else:
            raise Exception("Failed to generate access token.")
    except Exception as e:
        print(f"Error generating access token: {e}")
        exit()

# Function to fetch data from the API
def fetch_data(start_date, end_date, auth_token):
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json"
    }
    all_data = []
    skip = 0
    top = 10000

    while True:
        params = {
            "startdate": start_date,
            "enddate": end_date,
            "top": top,
            "skip": skip
        }
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()

        if "completedContacts" in data and data["completedContacts"]:
            all_data.extend(data["completedContacts"])
            skip += top
            if len(data["completedContacts"]) < top:
                break
        else:
            break

    print(f"Total records fetched: {len(all_data)}")
    return all_data

# Save data to CSV
def save_data_to_csv(data):
    df = pd.DataFrame(data)
    csv_file = "completed_contacts.csv"
    df.to_csv(csv_file, index=False)
    print(f"Data saved to {csv_file}")
    return csv_file

# Create raw data table
def create_raw_table():
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    create_table_query = """
    CREATE TABLE IF NOT EXISTS completed_contacts (
        contact_id VARCHAR(50),
        contact_start_date TIMESTAMP,
        last_update_time TIMESTAMP,
        from_address VARCHAR(100),
        to_address VARCHAR(100),
        media_type VARCHAR(50),
        is_outbound BOOLEAN,
        master_contact_id VARCHAR(50)
    );
    """
    cursor.execute(create_table_query)
    conn.commit()
    cursor.close()
    conn.close()

# Insert raw data into PostgreSQL
def insert_raw_data_to_db(csv_file):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    df = pd.read_csv(csv_file)
    for _, row in df.iterrows():
        cursor.execute(
            """
            INSERT INTO completed_contacts (contact_id, contact_start_date, last_update_time, from_address, to_address, media_type, is_outbound, master_contact_id)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """,
            (row['contactId'], row['contactStartDate'], row['lastUpdateTime'], row['fromAddress'],
             row['toAddress'], row['mediaType'], row['isOutbound'], row['masterContactId'])
        )
    conn.commit()
    cursor.close()
    conn.close()

# Function to filter and summarize data
def filter_and_summarize_data():
    conn = psycopg2.connect(**DB_CONFIG)
    df = pd.read_sql("SELECT * FROM completed_contacts", conn)
    conn.close()

    # Filtering conditions
    filtered_df = df[
        (df['media_type'] == '4') &
        (df['is_outbound'] == False) &
        (df['master_contact_id'] == df['contact_id']) &
        (df['abandoned'] == False) &
        (df['agentSeconds'] == 0) &
        (df['inQueueSeconds'] == 0) &
        (df['preQueueSeconds'] > 1)
    ]

    # Summarize the data
    summary = filtered_df.groupby('to_address').agg(
        offered_calls=('contact_id', 'count'),
        answered_calls=('contact_id', 'count'),
        ivr_abandon=('abandoned', 'sum')
    ).reset_index()

    print("Filtered and summarized data")
    return summary

# Save summary data to PostgreSQL
def save_summary_to_db(summary_data):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS dashboard_summary (
            to_address VARCHAR(100),
            offered_calls INT,
            answered_calls INT,
            ivr_abandon INT
        );
    """)

    for _, row in summary_data.iterrows():
        cursor.execute(
            """
            INSERT INTO dashboard_summary (to_address, offered_calls, answered_calls, ivr_abandon)
            VALUES (%s, %s, %s, %s)
            """,
            (row['to_address'], row['offered_calls'], row['answered_calls'], row['ivr_abandon'])
        )
    conn.commit()
    cursor.close()
    conn.close()

# Main Execution Flow
if __name__ == "__main__":
    auth_token = get_access_token()
    end_date = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')
    start_date = (datetime.now(timezone.utc) - timedelta(hours=2)).strftime('%Y-%m-%dT%H:%M:%SZ')

    # Fetch and save raw data
    create_raw_table()
    data = fetch_data(start_date, end_date, auth_token)
    csv_file = save_data_to_csv(data)
    insert_raw_data_to_db(csv_file)

    # Filter and summarize data
    summary_data = filter_and_summarize_data()
    save_summary_to_db(summary_data)

    # Delete CSV
    os.remove(csv_file)
    print("Data processing complete.")
