import requests
import psycopg2
from psycopg2.extras import execute_values
from datetime import datetime, timedelta, timezone
import json

# API and DB Configurations
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"
DB_CONFIG = {
    "host": "172.16.130.247",
    "database": "postgres",
    "user": "postgres",
    "password": "Zxcv@1234"
}

def get_access_token():
    try:
        response = requests.post(ACCESS_TOKEN_URL)
        response_data = response.json()
        if "access_token" in response_data:
            print("Access Token generated successfully.")
            return response_data['access_token']
        else:
            raise Exception("Failed to generate access token.")
    except Exception as e:
        print(f"Error generating access token: {e}")
        exit()

def fetch_data(start_date, end_date, auth_token):
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json"
    }
    all_data = []
    skip = 0
    top = 10000

    while True:
        params = {
            "startdate": start_date,
            "enddate": end_date,
            "top": top,
            "skip": skip
        }
        response = requests.get(API_URL, headers=headers, params=params)
        if response.status_code != 200:
            raise Exception(f"API request failed with status code {response.status_code}: {response.text}")

        data = response.json()
        if "completedContacts" in data and data["completedContacts"]:
            all_data.extend(data["completedContacts"])
            skip += top
            if len(data["completedContacts"]) < top:
                break
        else:
            break

    print(f"Total records fetched: {len(all_data)}")
    return all_data

def save_to_postgres(data):
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        # Create table if not exists
        create_table_query = """
        CREATE TABLE IF NOT EXISTS completed_contacts (
            contact_id BIGINT PRIMARY KEY,  -- Unique identifier for each contact
            abandoned BOOLEAN DEFAULT FALSE,
            abandon_seconds INTEGER,
            acw_seconds INTEGER,
            agent_id BIGINT,
            agent_seconds INTEGER,
            callback_time BIGINT,
            campaign_id BIGINT,
            campaign_name TEXT,
            conf_seconds INTEGER,
            contact_start TIMESTAMP,
            date_acw_warehoused TIMESTAMP,
            date_contact_warehoused TIMESTAMP,
            disposition_notes TEXT,
            end_reason TEXT,
            first_name TEXT,
            last_name TEXT,
            from_addr TEXT,
            hold_count INTEGER,
            hold_seconds INTEGER,
            in_queue_seconds INTEGER,
            is_logged BOOLEAN DEFAULT FALSE,
            is_outbound BOOLEAN DEFAULT FALSE,
            is_refused BOOLEAN DEFAULT FALSE,
            is_short_abandon BOOLEAN DEFAULT FALSE,
            is_takeover BOOLEAN DEFAULT FALSE,
            is_warehoused BOOLEAN DEFAULT FALSE,
            last_update_time TIMESTAMP,
            master_contact_id BIGINT,
            media_type_id INTEGER,
            media_type_name TEXT,
            media_sub_type_id INTEGER,
            media_sub_type_name TEXT,
            point_of_contact_id BIGINT,
            point_of_contact_name TEXT,
            post_queue_seconds INTEGER,
            pre_queue_seconds INTEGER,
            primary_disposition_id INTEGER,
            refuse_reason TEXT,
            refuse_time TIMESTAMP,
            release_seconds INTEGER,
            routing_time BIGINT,
            secondary_disposition_id INTEGER,
            service_level_flag TEXT,
            skill_id INTEGER,
            skill_name TEXT,
            tags INTEGER,
            team_id BIGINT,
            team_name TEXT,
            to_addr TEXT,
            total_duration_seconds INTEGER,
            transfer_indicator_id INTEGER,
            transfer_indicator_name TEXT,
            is_analytics_processed BOOLEAN DEFAULT FALSE,
            analytics_processed_date TIMESTAMP,
            raw_data JSONB -- Store the full raw response as JSONB
        );
        """
        cursor.execute(create_table_query)

        # Insert data into the table
        insert_query = """
        INSERT INTO completed_contacts (
            contact_id, abandoned, abandon_seconds, acw_seconds, agent_id, agent_seconds, 
            callback_time, campaign_id, campaign_name, conf_seconds, contact_start, 
            date_acw_warehoused, date_contact_warehoused, disposition_notes, end_reason, 
            first_name, last_name, from_addr, hold_count, hold_seconds, in_queue_seconds, 
            is_logged, is_outbound, is_refused, is_short_abandon, is_takeover, 
            is_warehoused, last_update_time, master_contact_id, media_type_id, 
            media_type_name, media_sub_type_id, media_sub_type_name, point_of_contact_id, 
            point_of_contact_name, post_queue_seconds, pre_queue_seconds, 
            primary_disposition_id, refuse_reason, refuse_time, release_seconds, 
            routing_time, secondary_disposition_id, service_level_flag, skill_id, 
            skill_name, tags, team_id, team_name, to_addr, total_duration_seconds, 
            transfer_indicator_id, transfer_indicator_name, is_analytics_processed, 
            analytics_processed_date, raw_data
        ) VALUES %s
        ON CONFLICT (contact_id) DO NOTHING;
        """

        # Prepare data for insertion
        records = [
            (
                record.get("contactId"),
                record.get("abandoned", False),
                record.get("abandonSeconds"),
                int(record["ACWSeconds"]) if record.get("ACWSeconds") else None,
                record.get("agentId"),
                record.get("agentSeconds"),
                int(record["callbackTime"]) if record.get("callbackTime") else None,
                record.get("campaignId"),
                record.get("campaignName"),
                record.get("confSeconds"),
                record.get("contactStart"),
                record.get("dateACWWarehoused"),
                record.get("dateContactWarehoused"),
                record.get("dispositionNotes"),
                record.get("endReason"),
                record.get("firstName"),
                record.get("lastName"),
                record.get("fromAddr"),
                record.get("holdCount"),
                record.get("holdSeconds"),
                record.get("inQueueSeconds"),
                record.get("isLogged", False),
                record.get("isOutbound", False),
                record.get("isRefused", False),
                record.get("isShortAbandon", False),
                record.get("isTakeover", False),
                record.get("isWarehoused", False),
                record.get("lastUpdateTime"),
                record.get("masterContactId"),
                record.get("mediaTypeId"),
                record.get("mediaTypeName"),
                record.get("mediaSubTypeID"),
                record.get("mediaSubTypeName"),
                record.get("pointOfContactId"),
                record.get("pointOfContactName"),
                record.get("postQueueSeconds"),
                record.get("preQueueSeconds"),
                record.get("primaryDispositionid"),
                record.get("refuseReason"),
                record.get("refuseTime"),
                record.get("releaseSeconds"),
                record.get("routingTime"),
                record.get("secondaryDispositionid"),
                record.get("serviceLevelFlag"),
                record.get("skillId"),
                record.get("skillName"),
                record.get("tags"),
                record.get("teamId"),
                record.get("teamName"),
                record.get("toAddr"),
                record.get("totalDurationSeconds"),
                record.get("transferIndicatorId"),
                record.get("transferIndicatorName"),
                record.get("isAnalyticsProcessed", False),
                record.get("analyticsProcessedDate"),
                json.dumps(record)
            )
            for record in data
        ]

        execute_values(cursor, insert_query, records)
        conn.commit()
        print("Data saved to PostgreSQL successfully.")

    except Exception as e:
        print(f"Error saving data to PostgreSQL: {e}")

    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

if __name__ == "__main__":
    auth_token = get_access_token()

    # Set the time range for the last 2 hours
    end_date = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')
    start_date = (datetime.now(timezone.utc) - timedelta(hours=2)).strftime('%Y-%m-%dT%H:%M:%SZ')

    data = fetch_data(start_date, end_date, auth_token)
    if data:
        save_to_postgres(data)
    else:
        print("No data fetched for the given time range.")

