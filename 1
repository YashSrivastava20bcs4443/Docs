import requests
import json
import pandas as pd
import psycopg2
from psycopg2 import sql
from datetime import datetime, timedelta, timezone

# Database configuration
DB_CONFIG = {
    "host": "172.16.130.247",
    "database": "postgres",
    "user": "postgres",
    "password": "Zxcv@1234"
}

# API details
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"

# Function to generate an access token
def get_access_token():
    try:
        response = requests.post(ACCESS_TOKEN_URL)
        response_data = response.json()
        if "access_token" in response_data:
            print("Access Token generated successfully.")
            return response_data['access_token']
        else:
            raise Exception("Failed to generate access token.")
    except Exception as e:
        print(f"Error generating access token: {e}")
        exit()

# Function to fetch data from API
def fetch_data(start_date, end_date, auth_token):
    headers = {"Authorization": f"Bearer {auth_token}", "Content-Type": "application/json"}
    all_data = []
    skip = 0
    top = 10000  # Fetch 10,000 records at a time

    while True:
        params = {"startdate": start_date, "enddate": end_date, "top": top, "skip": skip}
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()
        if "completedContacts" in data and data["completedContacts"]:
            all_data.extend(data["completedContacts"])
            skip += top
            if len(data["completedContacts"]) < top:
                break
        else:
            break

    print(f"Total records fetched: {len(all_data)}")
    return all_data

# Function to create tables if they don't exist
def create_tables():
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        # Create raw data table
        raw_table_query = """
        CREATE TABLE IF NOT EXISTS raw_data (
            contact_id BIGINT,
            to_address VARCHAR(50),
            from_address VARCHAR(50),
            media_type_id INT,
            is_outbound BOOLEAN,
            abandoned BOOLEAN,
            agent_seconds INT,
            in_queue_seconds INT,
            pre_queue_seconds INT,
            end_reason VARCHAR(255),
            master_contact_id BIGINT,
            contact_start_date TIMESTAMP,
            last_update_time TIMESTAMP,
            PRIMARY KEY (contact_id)
        );
        """
        
        # Create processed data table
        processed_table_query = """
        CREATE TABLE IF NOT EXISTS processed_data (
            to_address VARCHAR(50) PRIMARY KEY,
            offered_calls INT,
            answered INT,
            ivr_abandon INT,
            queue_abandon INT,
            polite_disconnect INT
        );
        """

        # Execute the queries
        cursor.execute(raw_table_query)
        cursor.execute(processed_table_query)
        conn.commit()

        print("Tables created successfully (if not already existing).")
    except Exception as e:
        print(f"Error creating tables: {e}")
    finally:
        if conn:
            cursor.close()
            conn.close()

# Main function
def main():
    # Generate access token
    auth_token = get_access_token()

    # Fetch data from the API for the last 2 hours
    end_date = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')
    start_date = (datetime.now(timezone.utc) - timedelta(hours=2)).strftime('%Y-%m-%dT%H:%M:%SZ')
    data = fetch_data(start_date, end_date, auth_token)

    # Store raw data in a CSV
    if data:
        df = pd.DataFrame(data)
        raw_file = "raw_data.csv"
        df.to_csv(raw_file, index=False)
        print(f"Raw data saved to {raw_file}")

        # Create tables if they don't exist
        create_tables()

        # Push raw data to the database and process it
        process_and_store_data(df, raw_file)
    else:
        print("No data fetched for the given time range.")

# Function to process and store data in the database
def process_and_store_data(df, raw_file):
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        # Insert raw data into the raw_data table
        for _, row in df.iterrows():
            try:
                cursor.execute("""
                INSERT INTO raw_data (
                    contact_id, to_address, from_address, media_type_id, is_outbound, abandoned,
                    agent_seconds, in_queue_seconds, pre_queue_seconds, end_reason,
                    master_contact_id, contact_start_date, last_update_time
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (contact_id) DO NOTHING;
                """, (
                    row['contactId'], row['toAddr'], row['fromAddr'], row['mediaTypeId'], row['isOutbound'],
                    row['abandoned'], row['agentSeconds'], row['inQueueSeconds'], row['preQueueSeconds'],
                    row['endReason'], row['masterContactId'], row['contactStartDate'], row['lastUpdateTime']
                ))
            except Exception as e:
                print(f"Error inserting raw data: {e}")

        # Process data for the processed_data table
        processed_data = process_final_data(df)

        # Insert processed data into the processed_data table
        for row in processed_data.itertuples():
            cursor.execute("""
            INSERT INTO processed_data (
                to_address, offered_calls, answered, ivr_abandon, queue_abandon, polite_disconnect
            ) VALUES (%s, %s, %s, %s, %s, %s)
            ON CONFLICT (to_address) DO UPDATE
            SET offered_calls = EXCLUDED.offered_calls,
                answered = EXCLUDED.answered,
                ivr_abandon = EXCLUDED.ivr_abandon,
                queue_abandon = EXCLUDED.queue_abandon,
                polite_disconnect = EXCLUDED.polite_disconnect;
            """, (row.to_address, row.offered_calls, row.answered, row.ivr_abandon, row.queue_abandon, row.polite_disconnect))

        conn.commit()
        print("Data successfully inserted into the database.")

    except Exception as e:
        print(f"Error processing or storing data: {e}")
    finally:
        if conn:
            cursor.close()
            conn.close()

# Function to process final data for processed_data table
def process_final_data(df):
    # Add your logic here to filter and compute final processed data
    processed_data = pd.DataFrame()  # Replace with actual processing
    return processed_data

if __name__ == "__main__":
    main()
