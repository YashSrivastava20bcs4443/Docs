import requests
import json
import psycopg2
from datetime import datetime, timedelta, timezone

# API and Access Token Details
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"

# PostgreSQL Connection Details
DB_CONFIG = {
    "host": "172.16.130.247",
    "database": "postgres",
    "user": "postgres",
    "password": "Zxcv@1234"
}

# Generate Access Token
def get_access_token():
    try:
        response = requests.post(ACCESS_TOKEN_URL)
        response_data = response.json()
        if "access_token" in response_data:
            print("Access Token generated successfully.")
            return response_data['access_token']
        else:
            raise Exception("Failed to generate access token.")
    except Exception as e:
        print(f"Error generating access token: {e}")
        exit()

# Fetch data from API
def fetch_data(start_date, end_date, auth_token):
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json"
    }
    all_data = []
    skip = 0
    top = 10000  

    while True:
        params = {
            "startdate": start_date,
            "enddate": end_date,
            "top": top,
            "skip": skip
        }
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()

        if "completedContacts" in data and data["completedContacts"]:
            all_data.extend(data["completedContacts"])
            skip += top
            if len(data["completedContacts"]) < top:
                break
        else:
            break

    print(f"Total records fetched: {len(all_data)}")
    return all_data

# Store raw data in PostgreSQL
def store_raw_data(data):
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        # Create the table if it does not exist
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS raw_data (
            id SERIAL PRIMARY KEY,
            contact_id INTEGER,
            master_contact_id INTEGER,
            media_type INTEGER,
            is_outbound BOOLEAN,
            abandoned BOOLEAN,
            agent_seconds INTEGER,
            in_queue_seconds INTEGER,
            pre_queue_seconds INTEGER,
            end_reason VARCHAR,
            to_addr VARCHAR
        );
        """)
        conn.commit()

        # Insert raw data into the table
        for record in data:
            cursor.execute("""
            INSERT INTO raw_data (contact_id, master_contact_id, media_type, is_outbound, abandoned,
                                  agent_seconds, in_queue_seconds, pre_queue_seconds, end_reason, to_addr)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);
            """, (
                record.get("contactId"),
                record.get("masterContactId"),
                record.get("mediaType"),
                record.get("isOutbound"),
                record.get("abandoned"),
                record.get("agentSeconds"),
                record.get("inQueueSeconds"),
                record.get("preQueueSeconds"),
                record.get("endReason"),
                record.get("toAddr"),
            ))
        conn.commit()
        print("Raw data stored successfully.")
    except Exception as e:
        print(f"Error storing raw data: {e}")
    finally:
        if conn:
            cursor.close()
            conn.close()

# Filter data for metrics and store in another table
def store_filtered_data():
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        # Create the table for filtered data
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS filtered_data (
            to_addr VARCHAR PRIMARY KEY,
            offered_calls INTEGER,
            answered_calls INTEGER,
            ivr_abandon INTEGER,
            queue_abandon INTEGER,
            polite_disconnect INTEGER
        );
        """)
        conn.commit()

        # Filter data and calculate metrics
        cursor.execute("""
        INSERT INTO filtered_data (to_addr, offered_calls, answered_calls, ivr_abandon, queue_abandon, polite_disconnect)
        SELECT 
            to_addr,
            COUNT(*) AS offered_calls,
            COUNT(*) FILTER (WHERE abandoned = FALSE AND agent_seconds > 0) AS answered_calls,
            COUNT(*) FILTER (WHERE abandoned = FALSE AND agent_seconds = 0 AND in_queue_seconds = 0 AND pre_queue_seconds > 1 AND end_reason = 'Contact Hung Up') AS ivr_abandon,
            COUNT(*) FILTER (WHERE abandoned = FALSE AND is_outbound = TRUE AND agent_seconds = 0 AND in_queue_seconds > 0 AND pre_queue_seconds > 0) AS queue_abandon,
            COUNT(*) FILTER (WHERE abandoned = FALSE AND agent_seconds = 0 AND in_queue_seconds = 0 AND pre_queue_seconds > 1 AND end_reason = 'Contact Hang Up via Script') AS polite_disconnect
        FROM raw_data
        WHERE media_type = 4 AND is_outbound = FALSE AND master_contact_id = contact_id
        GROUP BY to_addr;
        """)
        conn.commit()
        print("Filtered data stored successfully.")
    except Exception as e:
        print(f"Error storing filtered data: {e}")
    finally:
        if conn:
            cursor.close()
            conn.close()

# Main Execution Flow
if __name__ == "__main__":
    # Generate Access Token
    auth_token = get_access_token()

    # Set the time range for the last 2 hours
    end_date = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')
    start_date = (datetime.now(timezone.utc) - timedelta(hours=2)).strftime('%Y-%m-%dT%H:%M:%SZ')

    # Fetch data from the API
    data = fetch_data(start_date, end_date, auth_token)
    if data:
        print("Data fetched successfully.")
        # Store raw data
        store_raw_data(data)
        # Filter and store filtered data
        store_filtered_data()
    else:
        print("No data fetched for the given time range.")

