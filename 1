import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import IsolationForest
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Load data
file_path = 'data.xlsx'
df = pd.read_excel(file_path)
df['@timestamp'] = pd.to_datetime(df['@timestamp'])
df.set_index('@timestamp', inplace=True)

# Aggregate daily alerts
data = df.resample('D').size().rename('AlertCount')
data = data.fillna(0)

# Streamlit Dashboard
st.title("Advanced Alert Analysis and Prediction")

# Display raw data
st.subheader("Raw Data")
st.dataframe(data.reset_index().rename(columns={'@timestamp': 'Date'}))

# Anomaly Detection
st.subheader("Anomaly Detection with Isolation Forest")
contamination = st.slider("Select contamination (proportion of anomalies):", 0.01, 0.2, 0.05)
if contamination:
    isolation_forest = IsolationForest(contamination=contamination, random_state=42)
    data['Anomaly'] = isolation_forest.fit_predict(data.values.reshape(-1, 1))
    data['Anomaly'] = data['Anomaly'].map({1: 'Normal', -1: 'Anomaly'})

    fig, ax = plt.subplots(figsize=(12, 6))
    sns.lineplot(data=data, x=data.index, y='AlertCount', hue='Anomaly', palette=['red', 'blue'], ax=ax)
    ax.set_title("Anomaly Detection")
    ax.set_ylabel("Number of Alerts")
    ax.set_xlabel("Date")
    st.pyplot(fig)

    st.write("Anomaly Breakdown:")
    st.dataframe(data.groupby('Anomaly')['AlertCount'].agg(['count', 'mean']))
    

# Predictive Analysis with LSTM
st.subheader("Predictive Analysis with LSTM")

# Normalize the data
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data['AlertCount'].values.reshape(-1, 1))

# Sequence preparation for LSTM
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

seq_length = st.slider("Select sequence length (days):", 7, 60, 30)
X, y = create_sequences(data_scaled, seq_length)

# Split into training and testing sets
train_size = int(0.8 * len(X))
X_train, y_train = X[:train_size], y[:train_size]
X_test, y_test = X[train_size:], y[train_size:]

# Build and train the LSTM model
if st.button("Train LSTM Model"):
    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
        LSTM(50, return_sequences=False),
        Dense(25),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error')
    history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test), verbose=1)

    # Predict and inverse transform
    predicted = model.predict(X_test)
    predicted = scaler.inverse_transform(predicted)
    y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

    # Plot predictions
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.plot(data.index[-len(y_test):], y_test_actual, label='Actual', marker='o')
    ax.plot(data.index[-len(y_test):], predicted, label='Predicted', marker='o', linestyle='--')
    ax.set_title("LSTM Forecast vs Actual")
    ax.set_xlabel("Date")
    ax.set_ylabel("Number of Alerts")
    ax.legend()
    st.pyplot(fig)

    # Display model training loss
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.plot(history.history['loss'], label='Training Loss')
    ax.plot(history.history['val_loss'], label='Validation Loss')
    ax.set_title("Model Training Loss")
    ax.set_xlabel("Epoch")
    ax.set_ylabel("Loss")
    ax.legend()
    st.pyplot(fig)

# Export results
st.subheader("Export Results")
if st.button("Download Anomaly Data"):
    st.download_button(
        label="Download Anomaly Data",
        data=data.reset_index().to_csv(index=False).encode('utf-8'),
        file_name='anomaly_data.csv',
        mime='text/csv'
    )
