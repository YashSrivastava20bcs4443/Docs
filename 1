import csv
from elasticsearch import Elasticsearch
from demo_config import e_password, e_username, elasticsearch_url

# Elasticsearch client setup
es = Elasticsearch(
    [elasticsearch_url],
    basic_auth=(e_username, e_password)
)

# Function to fetch all alerts using scroll API and save them as CSV
def fetch_and_save_all_alerts_to_csv():
    common_index = "common-events-*"
    query = {
        "query": {
            "bool": {
                "must": [
                    {"range": {
                        "@timestamp": {
                            "gte": "now-41d",
                            "lte": "now",
                            "format": "strict_date_optional_time"
                        }
                    }},
                    {"match": {"EventSource": "Airflow"}}
                ]
            }
        },
        "sort": [{"@timestamp": {"order": "desc"}}],  # Sort by most recent first
        "size": 1000  # Batch size for each scroll
    }

    try:
        # Initialize scrolling
        response = es.search(index=common_index, body=query, scroll="2m")  # Scroll context valid for 2 minutes
        scroll_id = response["_scroll_id"]  # Get scroll ID
        total_hits = response['hits']['total']['value']
        print(f"Total alerts found: {total_hits}")

        # Open CSV file for writing
        with open("all_airflow_alerts.csv", "w", newline="") as csvfile:
            csv_writer = csv.writer(csvfile)
            
            # Write header row (based on the keys in the first document)
            if total_hits > 0:
                first_hit = response['hits']['hits'][0]['_source']
                headers = list(first_hit.keys())
                csv_writer.writerow(headers)

            # Collect results and write to CSV
            while len(response['hits']['hits']) > 0:
                for hit in response['hits']['hits']:
                    row = [hit['_source'].get(header, "") for header in headers]
                    csv_writer.writerow(row)
                
                # Fetch next batch
                response = es.scroll(scroll_id=scroll_id, scroll="2m")

        print("Data successfully saved to 'all_airflow_alerts.csv'.")

    except Exception as e:
        print(f"Error fetching alerts: {e}")

# Main function
def process_alerts():
    fetch_and_save_all_alerts_to_csv()

if __name__ == "__main__":
    process_alerts()
