import streamlit as st
import requests
import pandas as pd
from datetime import datetime, timedelta, timezone
import pytz
import plotly.express as px

# API endpoints
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"

# Function to get access token
def get_access_token():
    response = requests.post(ACCESS_TOKEN_URL)
    response_data = response.json()
    if "access token" in response_data:
        return response_data['access token']
    raise Exception("Failed to generate access token")

# Function to fetch data from the API
def fetch_data(start_date, end_date, auth_token):
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json"
    }
    all_data = []
    skip = 0
    top = 10000
    while True:
        params = {
            "startdate": start_date,
            "enddate": end_date,
            "top": top,
            "skip": skip
        }
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()
        if "completedContacts" in data:
            contacts = data["completedContacts"]
            all_data.extend(contacts)
            skip += top
            if len(contacts) < top:
                break
        else:
            break
    return all_data

# Function to generate a summary based on contact data
def generate_summary(df):
    df['contactStartDate'] = pd.to_datetime(df['contactStartDate'])
    df['contactStartDate'] = df['contactStartDate'].dt.tz_convert('US/Eastern')
    
    summary_df = df.groupby('toAddress').agg(
        offered_calls=('contactId', 'count'),
        answered=('agentSeconds', lambda x: (x > 0).sum()),
        ivr_abandon=('preQueueSeconds', lambda x: ((x > 0) & (df['inQueueSeconds'] == 0)).sum()),
        polite_disconnect=('endReason', lambda x: ((x == 'Contact Hung Up') | (x == 'Contact Hang Up via Script')).sum()),
        queue_abandon=('inQueueSeconds', lambda x: (x > 0).sum()),
    ).reset_index()
    
    return summary_df

# Function to generate IVR bucket summary
def generate_ivr_bucket_summary(df):
    df['contactStartDate'] = pd.to_datetime(df['contactStartDate'])
    df['contactStartDate'] = df['contactStartDate'].dt.tz_convert('US/Eastern')
    df['preQueueSeconds'] = pd.to_numeric(df['preQueueSeconds'], errors='coerce').fillna(0)
    df['time_interval'] = df['contactStartDate'].dt.floor('30min')
    
    # Create IVR bucket based on preQueueSeconds
    df['ivr_bucket'] = pd.cut(
        df['preQueueSeconds'],
        bins=[0, 30, 60, 120, float('inf')],
        labels=['0-30s', '30-60s', '60-120s', '>120s'],
        right=False
    )
    
    # Grouping by time_interval for offered calls
    summary = df.groupby('time_interval').agg(
        Offered_Calls=('contactStartDate', 'count'),
        IVR_Abandon=('ivr_bucket', lambda x: (x.notna()).sum())
    ).reset_index()
    
    # Pivot table for bucket counts
    bucket_counts = df.pivot_table(
        index='time_interval',
        columns='ivr_bucket',
        values='contactStartDate',
        aggfunc='count',
        fill_value=0
    ).reset_index()
    
    # Merge summaries
    final_summary = pd.merge(summary, bucket_counts, on='time_interval', how='left')
    final_summary.columns = ['Interval', 'Offered Calls', 'IVR Abandon', '0-30s', '30-60s', '60-120s', '>120s']
    
    return final_summary

# Streamlit App
st.title("Live Dashboard for Completed Contacts")

# Get the token and set time range (last 1 hour)
try:
    auth_token = get_access_token()
except Exception as e:
    st.error(f"Error getting auth token: {e}")
    st.stop()

# Define date range in US/Eastern timezone
eastern = pytz.timezone('US/Eastern')
end_dt = datetime.now(timezone.utc).astimezone(eastern)
start_dt = end_dt - timedelta(hours=1)

end_date = end_dt.strftime('%Y-%m-%dT%H:%M:%SZ')
start_date = start_dt.strftime('%Y-%m-%dT%H:%M:%SZ')

# Fetch data
data = fetch_data(start_date, end_date, auth_token)

if data:
    df = pd.DataFrame(data)
    
    st.write("### Raw Data")
    st.dataframe(df)  # Original raw data view

    # Create a logically mapped raw data table for the real-time dashboard
    st.write("### Real-Time Contact Center Data")
    # For a clearer dashboard, rename and reorder columns as needed.
    # (Adjust the keys based on the API's response structure.)
    mapped_df = df.rename(columns={
        'contactStartDate': 'Start Date',
        'contactId': 'Contact ID',
        'agentSeconds': 'Agent Duration (sec)',
        'preQueueSeconds': 'Pre-Queue Duration (sec)',
        'inQueueSeconds': 'Queue Duration (sec)',
        'endReason': 'Call End Reason',
        'toAddress': 'Contact Address'
    })
    
    # Reorder columns for better logical mapping (if all columns exist)
    desired_order = ['Start Date', 'Contact ID', 'Contact Address',
                     'Agent Duration (sec)', 'Pre-Queue Duration (sec)',
                     'Queue Duration (sec)', 'Call End Reason']
    # Only include columns that exist in the DataFrame
    desired_order = [col for col in desired_order if col in mapped_df.columns]
    
    st.dataframe(mapped_df[desired_order])
    
    # Display summary data
    summary_df = generate_summary(df)
    st.write("### TFN-Wise Summary Data")
    st.dataframe(summary_df.style.background_gradient(cmap='viridis'))
    
    # Display IVR bucket summary
    ivr_bucket_summary_df = generate_ivr_bucket_summary(df)
    st.write("### IVR Abandon Bucket Wise Data")
    st.dataframe(ivr_bucket_summary_df.style.background_gradient(cmap='plasma'))
else:
    st.write("No data fetched for the given time range.")
