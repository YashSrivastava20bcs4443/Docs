import requests
import pandas as pd
from datetime import datetime, timedelta

# Prometheus server details
prometheus_url = 'http://<prometheus-server>:<port>/api/v1/query_range'

# Your specific queries
cpu_query = '100 - (avg by(instance) (rate(node_cpu_seconds_total{job="Linux_Servers", mode="idle"}[2m])) * 100)'
memory_query = '100 - (100 * (avg_over_time(node_memory_MemFree_bytes{job="Linux_Servers"}[2m]) + avg_over_time(node_memory_Cached_bytes{job="Linux_Servers"}[2m]) + avg_over_time(node_memory_Buffers_bytes{job="Linux_Servers"}[2m])) / avg_over_time(node_memory_MemTotal_bytes{job="Linux_Servers"}[2m]))'

# Time range parameters
end_time = datetime.now()  # Current time
start_time = end_time - timedelta(days=15)  # 15 days ago

# Convert times to UNIX timestamps
start_timestamp = int(start_time.timestamp())
end_timestamp = int(end_time.timestamp())

# Function to fetch range data from Prometheus
def fetch_prometheus_range_data(query, start, end, step):
    params = {
        'query': query,
        'start': start,
        'end': end,
        'step': step
    }
    response = requests.get(prometheus_url, params=params)
    if response.status_code == 200:
        return response.json()
    else:
        print(f"Failed to fetch data: {response.status_code}")
        return None

# Fetch CPU data for last 15 days with 1-hour step
cpu_data = fetch_prometheus_range_data(cpu_query, start_timestamp, end_timestamp, '1h')
# Fetch Memory data for last 15 days with 1-hour step
memory_data = fetch_prometheus_range_data(memory_query, start_timestamp, end_timestamp, '1h')

# Function to process Prometheus data into a DataFrame
def process_prometheus_data(data, metric_name):
    if not data or 'data' not in data or 'result' not in data['data']:
        return pd.DataFrame()
    
    records = []
    for item in data['data']['result']:
        instance = item['metric'].get('instance', 'unknown')  # Extract instance/server name
        for value in item['values']:
            timestamp = datetime.fromtimestamp(value[0])
            records.append({
                'date': timestamp.date(),  # Extract date only
                'instance': instance,
                metric_name: float(value[1])
            })
    
    # Convert to DataFrame
    df = pd.DataFrame(records)
    return df

# Convert CPU data to DataFrame
cpu_df = process_prometheus_data(cpu_data, 'cpu_usage')

# Convert Memory data to DataFrame
memory_df = process_prometheus_data(memory_data, 'memory_usage')

# Merge CPU and Memory DataFrames on 'date' and 'instance'
merged_df = pd.merge(cpu_df, memory_df, on=['date', 'instance'], how='outer')

# Save the data to an Excel file
output_file = 'prometheus_data.xlsx'
with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
    merged_df.to_excel(writer, sheet_name='CPU and Memory Usage', index=False)

print(f"Data saved successfully to {output_file}")
