import streamlit as st
import requests
import pandas as pd
from datetime import datetime, timedelta, timezone
import pytz
import plotly.express as px

# ----------------- API and Data Fetching Functions -----------------
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"

def get_access_token():
    response = requests.post(ACCESS_TOKEN_URL)
    response_data = response.json()
    if "access token" in response_data:
        return response_data['access token']
    raise Exception("Failed to generate access token")

def fetch_data(start_date, end_date, auth_token):
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json"
    }
    all_data = []
    skip = 0
    top = 10000
    while True:
        params = {
            "startdate": start_date,
            "enddate": end_date,
            "top": top,
            "skip": skip
        }
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()
        if "completedContacts" in data:
            contacts = data["completedContacts"]
            all_data.extend(contacts)
            skip += top
            if len(contacts) < top:
                break
        else:
            break
    return all_data

# ----------------- Data Transformation & Summary Functions -----------------
def generate_summary(df):
    # Convert contactStartDate to datetime and adjust timezone
    df['contactStartDate'] = pd.to_datetime(df['contactStartDate'], errors='coerce')
    df['contactStartDate'] = df['contactStartDate'].dt.tz_convert('US/Eastern')
    
    summary_df = df.groupby('toAddress').agg(
        offered_calls=('contactId', 'count'),
        answered=('agentSeconds', lambda x: (x > 0).sum()),
        ivr_abandon=('preQueueSeconds', lambda x: ((x > 0) & (df['inQueueSeconds'] == 0)).sum()),
        polite_disconnect=('endReason', lambda x: ((x == 'Contact Hung Up') | (x == 'Contact Hang Up via Script')).sum()),
        queue_abandon=('inQueueSeconds', lambda x: (x > 0).sum()),
    ).reset_index()
    
    return summary_df

def generate_ivr_bucket_summary(df):
    df['contactStartDate'] = pd.to_datetime(df['contactStartDate'], errors='coerce')
    df['contactStartDate'] = df['contactStartDate'].dt.tz_convert('US/Eastern')
    df['preQueueSeconds'] = pd.to_numeric(df['preQueueSeconds'], errors='coerce').fillna(0)
    df['time_interval'] = df['contactStartDate'].dt.floor('30min')
    
    # Create IVR bucket based on preQueueSeconds
    df['ivr_bucket'] = pd.cut(
        df['preQueueSeconds'],
        bins=[0, 30, 60, 120, float('inf')],
        labels=['0-30s', '30-60s', '60-120s', '>120s'],
        right=False
    )
    
    summary = df.groupby('time_interval').agg(
        Offered_Calls=('contactStartDate', 'count'),
        IVR_Abandon=('ivr_bucket', lambda x: (x.notna()).sum())
    ).reset_index()
    
    bucket_counts = df.pivot_table(
        index='time_interval',
        columns='ivr_bucket',
        values='contactStartDate',
        aggfunc='count',
        fill_value=0
    ).reset_index()
    
    final_summary = pd.merge(summary, bucket_counts, on='time_interval', how='left')
    final_summary.columns = ['Interval', 'Offered Calls', 'IVR Abandon', '0-30s', '30-60s', '60-120s', '>120s']
    
    return final_summary

def generate_kpi_metrics(df):
    # Ensure numeric columns are in proper format
    numeric_cols = ['agentSeconds', 'holdSeconds', 'inQueueSeconds', 'abandonSeconds', 'preQueueSeconds']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    total_calls = len(df)
    answered_calls = df[df['agentSeconds'] > 0].shape[0] if 'agentSeconds' in df.columns else 0
    
    # Determine abandoned calls using the 'abandoned' flag if exists, else logic
    if 'abandoned' in df.columns:
        df['abandoned_bool'] = df['abandoned'].astype(bool)
        abandoned_calls = df['abandoned_bool'].sum()
    else:
        abandoned_calls = df[(df['preQueueSeconds'] > 0) & (df['inQueueSeconds'] == 0)].shape[0]
    
    abandon_rate = (abandoned_calls / total_calls * 100) if total_calls > 0 else 0
    avg_agent_time = df['agentSeconds'].mean() if 'agentSeconds' in df.columns else 0
    avg_hold_time = df['holdSeconds'].mean() if 'holdSeconds' in df.columns else 0
    avg_wait_time = df['inQueueSeconds'].mean() if 'inQueueSeconds' in df.columns else 0
    
    return {
        "Total Calls": total_calls,
        "Answered Calls": answered_calls,
        "Abandoned Calls": abandoned_calls,
        "Abandon Rate (%)": round(abandon_rate, 2),
        "Avg Agent Time (sec)": round(avg_agent_time, 2),
        "Avg Hold Time (sec)": round(avg_hold_time, 2),
        "Avg Wait Time (sec)": round(avg_wait_time, 2)
    }

def generate_time_series(df):
    if 'contactStartDate' in df.columns:
        df['contactStartDate'] = pd.to_datetime(df['contactStartDate'], errors='coerce')
        df['minute_interval'] = df['contactStartDate'].dt.floor('T')
        ts = df.groupby('minute_interval').size().reset_index(name='Calls')
        return ts
    else:
        return pd.DataFrame(columns=['minute_interval', 'Calls'])

def generate_campaign_distribution(df):
    if 'campaignName' in df.columns:
        camp = df.groupby('campaignName').size().reset_index(name='Calls')
        return camp
    else:
        return pd.DataFrame(columns=['campaignName', 'Calls'])

def generate_end_reason_distribution(df):
    if 'endReason' in df.columns:
        er = df.groupby('endReason').size().reset_index(name='Calls')
        return er
    else:
        return pd.DataFrame(columns=['endReason', 'Calls'])

# ----------------- Streamlit App Layout -----------------
st.title("Real-Time Contact Center Dashboard")

# Get the token and set time range (last 1 hour)
try:
    auth_token = get_access_token()
except Exception as e:
    st.error(f"Error getting auth token: {e}")
    st.stop()

eastern = pytz.timezone('US/Eastern')
end_dt = datetime.now(timezone.utc).astimezone(eastern)
start_dt = end_dt - timedelta(hours=1)

# For API calls, we keep the ISO format with T and Z if required.
end_date = end_dt.strftime('%Y-%m-%dT%H:%M:%SZ')
start_date = start_dt.strftime('%Y-%m-%dT%H:%M:%SZ')

# Fetch data
data = fetch_data(start_date, end_date, auth_token)

if data:
    df = pd.DataFrame(data)
    
    st.write("### Raw Data")
    st.dataframe(df)  # Original raw data view

    # ----------------- Detailed Dashboard Table -----------------
    st.write("### Detailed Contact Center Data")
    col_mapping = {
        'abandoned': 'Abandoned',
        'abandonSeconds': 'Abandon Seconds',
        'acwseconds': 'ACW Seconds',
        'agentid': 'Agent ID',
        'agentSeconds': 'Agent Seconds',
        'analytics': 'Analytics',
        'ProcessedDate': 'Processed Date',
        'callbackTime': 'Callback Time',
        'campaignid': 'Campaign ID',
        'campaignName': 'Campaign Name',
        'conferenceSeconds': 'Conference Seconds',
        'contactId': 'Contact ID',
        'contactStartDate': 'Contact Start Date',
        'dateACWarehoused': 'Date AC Warehoused',
        'dateContactWarehoused': 'Date Contact Warehoused',
        'dispositionNotes': 'Disposition Notes',
        'endReason': 'End Reason',
        'firstName': 'First Name',
        'fromAddress': 'From Address',
        'highProficiency': 'High Proficiency',
        'holdCount': 'Hold Count',
        'holdSeconds': 'Hold Seconds',
        'inQueueSeconds': 'In Queue Seconds',
        'isAnalytics Processed': 'Is Analytics Processed',
        'isLogged': 'Is Logged',
        'isOutbound': 'Is Outbound',
        'isRefused': 'Is Refused',
        'isShortAbandon': 'Is Short Abandon',
        'isTakeover': 'Is Takeover',
        'lastName': 'Last Name',
        'lastUpdateTime': 'Last Update Time',
        'lowProficiency': 'Low Proficiency',
        'MasterContactId': 'Master Contact ID',
        'mediaSubTypeId': 'Media SubType ID',
        'mediaSubTypeflame': 'Media SubType Flame',
        'mediaTypeId': 'Media Type ID',
        'refuseTime': 'Refuse Time',
        'mediaTypeNane': 'Media Type Name',
        'releaseSeconds': 'Release Seconds',
        'pointOfContactid': 'Point of Contact ID',
        'pointOfContactName': 'Point of Contact Name',
        'postQueueSeconds': 'Post Queue Seconds',
        'preQueueSeconds': 'Pre Queue Seconds',
        'primaryDispositionId': 'Primary Disposition ID',
        'routing Time': 'Routing Time',
        'secondaryDispositionId': 'Secondary Disposition ID',
        'serviceLevelFlag': 'Service Level Flag',
        'skillid': 'Skill ID',
        'skillName': 'Skill Name',
        'transferIndicatorId': 'Transfer Indicator ID',
        'transfer': 'Transfer',
        'IndicatorName': 'Indicator Name'
    }
    
    dashboard_df = df.rename(columns=col_mapping)
    
    # Define a logical order of columns (only include those available)
    ordered_dashboard_columns = [
        "Contact Start Date", "Processed Date", "Callback Time", "Last Update Time",
        "Date AC Warehoused", "Date Contact Warehoused", "Contact ID", "Master Contact ID",
        "Campaign ID", "Campaign Name", "Agent ID", "First Name", "Last Name",
        "From Address", "Media Type ID", "Media Type Name", "Media SubType ID", "Media SubType Flame",
        "Pre Queue Seconds", "In Queue Seconds", "Post Queue Seconds", "Abandon Seconds",
        "ACW Seconds", "Agent Seconds", "Conference Seconds", "Hold Count", "Hold Seconds",
        "Release Seconds", "Refuse Time", "Routing Time", "End Reason", "Disposition Notes",
        "Primary Disposition ID", "Secondary Disposition ID", "Service Level Flag",
        "Abandoned", "Is Analytics Processed", "Analytics", "Is Logged", "Is Outbound",
        "Is Refused", "Is Short Abandon", "Is Takeover", "High Proficiency", "Low Proficiency",
        "Point of Contact ID", "Point of Contact Name", "Skill ID", "Skill Name",
        "Transfer Indicator ID", "Transfer", "Indicator Name"
    ]
    available_columns = [col for col in ordered_dashboard_columns if col in dashboard_df.columns]
    dashboard_df = dashboard_df[available_columns]
    
    # Reformat date columns to remove "T" and "Z" for display purposes.
    date_columns = ["Contact Start Date", "Processed Date", "Callback Time", 
                    "Last Update Time", "Date AC Warehoused", "Date Contact Warehoused"]
    for col in date_columns:
        if col in dashboard_df.columns:
            dashboard_df[col] = pd.to_datetime(dashboard_df[col], errors='coerce').dt.strftime("%Y-%m-%d %H:%M:%S")
    
    st.dataframe(dashboard_df)
    
    # ----------------- KPI Cards -----------------
    st.write("### Key Performance Indicators")
    kpi_metrics = generate_kpi_metrics(df)
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Total Calls", kpi_metrics["Total Calls"])
    col2.metric("Answered Calls", kpi_metrics["Answered Calls"])
    col3.metric("Abandoned Calls", kpi_metrics["Abandoned Calls"])
    col4.metric("Abandon Rate (%)", kpi_metrics["Abandon Rate (%)"])
    
    col5, col6, col7 = st.columns(3)
    col5.metric("Avg Agent Time (sec)", kpi_metrics["Avg Agent Time (sec)"])
    col6.metric("Avg Hold Time (sec)", kpi_metrics["Avg Hold Time (sec)"])
    col7.metric("Avg Wait Time (sec)", kpi_metrics["Avg Wait Time (sec)"])
    
    # ----------------- Time Series Chart -----------------
    st.write("### Calls Over Time (by Minute)")
    ts_df = generate_time_series(df)
    if not ts_df.empty:
        fig_ts = px.line(ts_df, x='minute_interval', y='Calls', 
                         title="Calls Over Time",
                         labels={"minute_interval": "Time", "Calls": "Number of Calls"})
        st.plotly_chart(fig_ts, use_container_width=True)
    else:
        st.write("Time series data not available.")
    
    # ----------------- Pie Chart: Call Disposition -----------------
    st.write("### Call Disposition Distribution")
    er_df = generate_end_reason_distribution(df)
    if not er_df.empty:
        fig_er = px.pie(er_df, names='endReason', values='Calls', 
                        title="Call Disposition Distribution")
        st.plotly_chart(fig_er, use_container_width=True)
    else:
        st.write("No call disposition data available.")
    
    # ----------------- Bar Chart: Calls by Campaign -----------------
    st.write("### Calls by Campaign")
    camp_df = generate_campaign_distribution(df)
    if not camp_df.empty:
        fig_camp = px.bar(camp_df, x='campaignName', y='Calls', 
                          title="Calls by Campaign", text='Calls')
        st.plotly_chart(fig_camp, use_container_width=True)
    else:
        st.write("No campaign data available.")
    
    # ----------------- Additional Summaries -----------------
    summary_df = generate_summary(df)
    st.write("### TFN-Wise Summary Data")
    st.dataframe(summary_df.style.background_gradient(cmap='viridis'))
    
    ivr_bucket_summary_df = generate_ivr_bucket_summary(df)
    st.write("### IVR Abandon Bucket Wise Data")
    st.dataframe(ivr_bucket_summary_df.style.background_gradient(cmap='plasma'))
    
else:
    st.write("No data fetched for the given time range.")
