import requests
import json
import csv
import psycopg2
from datetime import datetime, timedelta, timezone
import os

# API and Access Token Details
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"
DB_CONFIG = {
    "host": "172.16.130.247",
    "database": "postgres",
    "user": "postgres",
    "password": "Zxcv@1234"
}

# Generate Access Token
def get_access_token():
    try:
        response = requests.post(ACCESS_TOKEN_URL)
        response_data = response.json()
        if "access_token" in response_data:
            print("Access Token generated successfully.")
            return response_data['access_token']
        else:
            raise Exception("Failed to generate access token.")
    except Exception as e:
        print(f"Error generating access token: {e}")
        exit()

# Fetch data from API
def fetch_data(start_date, end_date, auth_token):
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json"
    }
    all_data = []
    skip = 0
    top = 10000  

    while True:
        params = {
            "startdate": start_date,
            "enddate": end_date,
            "top": top,
            "skip": skip
        }
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()

        if "completedContacts" in data and data["completedContacts"]:
            all_data.extend(data["completedContacts"])
            skip += top
            if len(data["completedContacts"]) < top:
                break
        else:
            break

    print(f"Total records fetched: {len(all_data)}")
    return all_data

# Save data to CSV
def save_to_csv(data, file_name):
    keys = data[0].keys()
    with open(file_name, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.DictWriter(file, fieldnames=keys)
        writer.writeheader()
        writer.writerows(data)
    print(f"Data saved to {file_name}")

# Filter data as per requirements
def filter_data(data):
    filtered_data = []
    for record in data:
        if record.get("mediaTypeId") == 4 and not record.get("isOutbound"):
            record_filtered = {
                "toAddress": record.get("toAddress"),
                "abandoned": record.get("abandoned"),
                "preQueueSeconds": record.get("preQueueSeconds"),
                "inQueueSeconds": record.get("inQueueSeconds"),
                "endReason": record.get("endReason"),
                "agentSeconds": record.get("agentSeconds"),
                "masterContactId": record.get("masterContactId"),
                "contactId": record.get("contactId"),
            }
            filtered_data.append(record_filtered)
    print(f"Filtered {len(filtered_data)} records.")
    return filtered_data

# Push raw data to database
def push_to_db(data, table_name):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    for record in data:
        placeholders = ", ".join(["%s"] * len(record))
        columns = ", ".join(record.keys())
        query = f"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})"
        cursor.execute(query, list(record.values()))
    conn.commit()
    cursor.close()
    conn.close()
    print(f"Data pushed to {table_name} table.")

# Create final table with processed data
def create_final_table(data, table_name):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    cursor.execute(f"""
        CREATE TABLE IF NOT EXISTS {table_name} (
            toAddress VARCHAR(15),
            offered_calls INT,
            answered INT,
            ivr_abandon INT,
            queue_abandon INT,
            polite_disconnect INT
        )
    """)
    conn.commit()

    # Add your logic to calculate final values
    for record in data:
        # Example calculation logic:
        # (you need to replace with actual calculation)
        cursor.execute(f"""
            INSERT INTO {table_name} (toAddress, offered_calls, answered, ivr_abandon, queue_abandon, polite_disconnect)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (record["toAddress"], 100, 90, 5, 3, 2))  # Example values
    conn.commit()
    cursor.close()
    conn.close()
    print(f"Final data inserted into {table_name} table.")

# Delete CSV file
def delete_csv(file_name):
    if os.path.exists(file_name):
        os.remove(file_name)
        print(f"{file_name} deleted.")
    else:
        print(f"{file_name} not found.")

# Main Execution Flow
if __name__ == "__main__":
    try:
        auth_token = get_access_token()

        # Set the time range for the last 2 hours
        end_date = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')
        start_date = (datetime.now(timezone.utc) - timedelta(hours=2)).strftime('%Y-%m-%dT%H:%M:%SZ')

        # Step 1: Fetch data
        raw_data = fetch_data(start_date, end_date, auth_token)

        # Step 2: Save raw data to CSV
        raw_csv_file = "raw_data.csv"
        save_to_csv(raw_data, raw_csv_file)

        # Step 3: Filter data
        filtered_data = filter_data(raw_data)

        # Step 4: Push raw data to DB
        push_to_db(raw_data, "raw_contacts")

        # Step 5: Create final table
        create_final_table(filtered_data, "processed_contacts")

        # Step 6: Delete CSV
        delete_csv(raw_csv_file)

    except Exception as e:
        print(f"An error occurred: {e}")
