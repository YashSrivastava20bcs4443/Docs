import requests
import pandas as pd
import psycopg2
from psycopg2 import sql

# Database configuration
DB_CONFIG = {
    'dbname': 'postgres',
    'user': 'postgres',
    'password': 'Zxcv@1234',
    'host': '172.16.130.247',
    'port': '5432'
}

# API Configuration
API_URL = "https://api.example.com/data"
API_HEADERS = {"Authorization": "Bearer YOUR_ACCESS_TOKEN"}

# Step 1: Fetch Data from API and Save to CSV
def fetch_and_save_to_csv():
    response = requests.get(API_URL, headers=API_HEADERS)
    data = response.json()
    
    # Convert data to dataframe and standardize column names
    df = pd.DataFrame(data)
    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')
    csv_file = "completed_contacts.csv"
    df.to_csv(csv_file, index=False)
    print(f"Total records fetched: {len(df)}")
    print("Data saved to completed_contacts.csv")
    return csv_file

# Step 2: Insert Raw CSV Data into PostgreSQL Table
def insert_raw_data_to_db(csv_file):
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        # Create table if not exists
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS completed_contacts (
                contact_id VARCHAR(50),
                contact_start_date TIMESTAMP,
                last_update_time TIMESTAMP,
                from_address VARCHAR(100),
                to_address VARCHAR(100),
                mediatype VARCHAR(50),
                isoutbound BOOLEAN,
                mastercontactid VARCHAR(50)
            );
        """)
        
        # Load data from CSV and insert into database
        df = pd.read_csv(csv_file)
        df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')
        
        for _, row in df.iterrows():
            cursor.execute("""
                INSERT INTO completed_contacts (
                    contact_id, contact_start_date, last_update_time, 
                    from_address, to_address, mediatype, isoutbound, mastercontactid
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                row['contactid'], row['contactstartdate'], row['lastupdatetime'],
                row['fromaddress'], row['toaddress'], row['mediatypename'],
                row['isoutbound'], row['mastercontactid']
            ))
        
        conn.commit()
        print("Data successfully inserted into completed_contacts.")
        cursor.close()
        conn.close()
    except Exception as e:
        print(f"Error inserting data into PostgreSQL: {e}")

# Step 3: Filter and Summarize the Data
def filter_and_summarize_data():
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        query = "SELECT * FROM completed_contacts"
        df = pd.read_sql_query(query, conn)
        
        # Apply filtering conditions
        filtered_data = df[(df['mediatype'] == '4') & (df['isoutbound'] == True)]
        print(f"Filtered records: {len(filtered_data)}")
        
        # Call summary function
        store_summary_to_postgresql(filtered_data)
        conn.close()
        return filtered_data
    except Exception as e:
        print(f"Error filtering data: {e}")

# Step 4: Store Filtered Summary Data in Another Database Table
def store_summary_to_postgresql(filtered_data):
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        # Create summary table if not exists
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS dashboard_summary (
                media_type VARCHAR(50),
                unique_toll_numbers INT,
                ivr_offered_count INT,
                ivr_abandon_count INT,
                polite_disconnect_count INT,
                queue_abandon_count INT
            );
        """)

        # Calculate metrics
        unique_toll_numbers = filtered_data['toaddress'].nunique()
        ivr_offered_count = len(filtered_data)
        ivr_abandon_count = len(filtered_data[filtered_data['prequeueseconds'] > 1])
        polite_disconnect_count = len(filtered_data[
            filtered_data['endreason'].isin(["Contact Hung Up", "Contact Hang Up via Script"])
        ])
        queue_abandon_count = len(filtered_data[filtered_data['inqueueseconds'] > 0])

        # Insert summary into PostgreSQL
        cursor.execute("""
            INSERT INTO dashboard_summary (media_type, unique_toll_numbers, ivr_offered_count, ivr_abandon_count, polite_disconnect_count, queue_abandon_count) 
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (
            '4',
            unique_toll_numbers,
            ivr_offered_count,
            ivr_abandon_count,
            polite_disconnect_count,
            queue_abandon_count
        ))

        conn.commit()
        print("Summary data successfully stored in PostgreSQL.")
        cursor.close()
        conn.close()
    except Exception as e:
        print(f"Error storing summary data: {e}")

# Main Execution Flow
if __name__ == "__main__":
    csv_file = fetch_and_save_to_csv()
    insert_raw_data_to_db(csv_file)
    filter_and_summarize_data()

