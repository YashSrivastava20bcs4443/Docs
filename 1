import streamlit as st
import requests
import pandas as pd
from datetime import datetime, timedelta, timezone
import pytz
import plotly.express as px
from streamlit_plotly_events import plotly_events  # For capturing click events

# ----------------- API and Data Fetching Functions -----------------
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"

def get_access_token():
    response = requests.post(ACCESS_TOKEN_URL)
    response_data = response.json()
    if "access token" in response_data:
        return response_data['access token']
    raise Exception("Failed to generate access token")

def fetch_data(start_date, end_date, auth_token):
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json"
    }
    all_data = []
    skip = 0
    top = 10000
    while True:
        params = {
            "startdate": start_date,
            "enddate": end_date,
            "top": top,
            "skip": skip
        }
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()
        if "completedContacts" in data:
            contacts = data["completedContacts"]
            all_data.extend(contacts)
            skip += top
            if len(contacts) < top:
                break
        else:
            break
    return all_data

# ----------------- Data Transformation & Summary Functions -----------------
def generate_summary(df):
    df['contactStartDate'] = pd.to_datetime(df['contactStartDate'], errors='coerce')
    df['contactStartDate'] = df['contactStartDate'].dt.tz_convert('US/Eastern')
    summary_df = df.groupby('toAddress').agg(
        offered_calls=('contactId', 'count'),
        answered=('agentSeconds', lambda x: (x > 0).sum()),
        ivr_abandon=('preQueueSeconds', lambda x: ((x > 0) & (df['inQueueSeconds'] == 0)).sum()),
        polite_disconnect=('endReason', lambda x: ((x == 'Contact Hung Up') | (x == 'Contact Hang Up via Script')).sum()),
        queue_abandon=('inQueueSeconds', lambda x: (x > 0).sum()),
    ).reset_index()
    return summary_df

def generate_ivr_bucket_summary(df):
    df['contactStartDate'] = pd.to_datetime(df['contactStartDate'], errors='coerce')
    df['contactStartDate'] = df['contactStartDate'].dt.tz_convert('US/Eastern')
    df['preQueueSeconds'] = pd.to_numeric(df['preQueueSeconds'], errors='coerce').fillna(0)
    df['time_interval'] = df['contactStartDate'].dt.floor('30min')
    df['ivr_bucket'] = pd.cut(
        df['preQueueSeconds'],
        bins=[0, 30, 60, 120, float('inf')],
        labels=['0-30s', '30-60s', '60-120s', '>120s'],
        right=False
    )
    summary = df.groupby('time_interval').agg(
        Offered_Calls=('contactStartDate', 'count'),
        IVR_Abandon=('ivr_bucket', lambda x: (x.notna()).sum())
    ).reset_index()
    bucket_counts = df.pivot_table(
        index='time_interval',
        columns='ivr_bucket',
        values='contactStartDate',
        aggfunc='count',
        fill_value=0
    ).reset_index()
    final_summary = pd.merge(summary, bucket_counts, on='time_interval', how='left')
    final_summary.columns = ['Interval', 'Offered Calls', 'IVR Abandon', '0-30s', '30-60s', '60-120s', '>120s']
    return final_summary

def generate_kpi_metrics(df):
    numeric_cols = ['agentSeconds', 'holdSeconds', 'inQueueSeconds', 'abandonSeconds', 'preQueueSeconds']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    total_calls = len(df)
    answered_calls = df[df['agentSeconds'] > 0].shape[0] if 'agentSeconds' in df.columns else 0
    if 'abandoned' in df.columns:
        df['abandoned_bool'] = df['abandoned'].astype(bool)
        abandoned_calls = df['abandoned_bool'].sum()
    else:
        abandoned_calls = df[(df['preQueueSeconds'] > 0) & (df['inQueueSeconds'] == 0)].shape[0]
    abandon_rate = (abandoned_calls / total_calls * 100) if total_calls > 0 else 0
    avg_agent_time = df['agentSeconds'].mean() if 'agentSeconds' in df.columns else 0
    avg_hold_time = df['holdSeconds'].mean() if 'holdSeconds' in df.columns else 0
    avg_wait_time = df['inQueueSeconds'].mean() if 'inQueueSeconds' in df.columns else 0
    avg_call_duration = avg_agent_time  # Using agentSeconds as a proxy
    return {
        "Total Calls": total_calls,
        "Answered Calls": answered_calls,
        "Abandoned Calls": abandoned_calls,
        "Abandon Rate (%)": round(abandon_rate, 2),
        "Avg Agent Time (sec)": round(avg_agent_time, 2),
        "Avg Hold Time (sec)": round(avg_hold_time, 2),
        "Avg Wait Time (sec)": round(avg_wait_time, 2),
        "Avg Call Duration (sec)": round(avg_call_duration, 2)
    }

def generate_time_series(df):
    if 'contactStartDate' in df.columns:
        df['contactStartDate'] = pd.to_datetime(df['contactStartDate'], errors='coerce')
        df['minute_interval'] = df['contactStartDate'].dt.floor('T')
        ts = df.groupby('minute_interval').size().reset_index(name='Calls')
        return ts
    else:
        return pd.DataFrame(columns=['minute_interval', 'Calls'])

def generate_campaign_distribution(df):
    if 'campaignName' in df.columns:
        camp = df.groupby('campaignName').size().reset_index(name='Calls')
        return camp
    else:
        return pd.DataFrame(columns=['campaignName', 'Calls'])

def generate_end_reason_distribution(df):
    if 'endReason' in df.columns:
        er = df.groupby('endReason').size().reset_index(name='Calls')
        return er
    else:
        return pd.DataFrame(columns=['endReason', 'Calls'])

def generate_top_agents(df, top_n=5):
    if "Agent ID" in df.columns:
        top_agents = df.groupby("Agent ID").size().reset_index(name="Calls")
        top_agents = top_agents.sort_values("Calls", ascending=False).head(top_n)
        return top_agents
    return pd.DataFrame(columns=["Agent ID", "Calls"])

# ----------------- Streamlit App Layout -----------------
st.title("niceLiveUCX Dashboard")

# Get token and set time range (last 1 hour)
try:
    auth_token = get_access_token()
except Exception as e:
    st.error(f"Error getting auth token: {e}")
    st.stop()

eastern = pytz.timezone('US/Eastern')
end_dt = datetime.now(timezone.utc).astimezone(eastern)
start_dt = end_dt - timedelta(hours=1)

# API calls use ISO format with T and Z if required.
end_date = end_dt.strftime('%Y-%m-%dT%H:%M:%SZ')
start_date = start_dt.strftime('%Y-%m-%dT%H:%M:%SZ')

# Fetch data
data = fetch_data(start_date, end_date, auth_token)

if data:
    df = pd.DataFrame(data)
    
    st.write("### Raw Data")
    st.dataframe(df)  # Original raw data view

    # ----------------- Detailed Dashboard Table -----------------
    st.write("### Detailed Contact Center Data")
    col_mapping = {
        'abandoned': 'Abandoned',
        'abandonSeconds': 'Abandon Seconds',
        'acwseconds': 'ACW Seconds',
        'agentid': 'Agent ID',
        'agentSeconds': 'Agent Seconds',
        'analytics': 'Analytics',
        'ProcessedDate': 'Processed Date',
        'callbackTime': 'Callback Time',
        'campaignid': 'Campaign ID',
        'campaignName': 'Campaign Name',
        'conferenceSeconds': 'Conference Seconds',
        'contactId': 'Contact ID',
        'contactStartDate': 'Contact Start Date',
        'dateACWarehoused': 'Date AC Warehoused',
        'dateContactWarehoused': 'Date Contact Warehoused',
        'dispositionNotes': 'Disposition Notes',
        'endReason': 'End Reason',
        'firstName': 'First Name',
        'fromAddress': 'From Address',
        'highProficiency': 'High Proficiency',
        'holdCount': 'Hold Count',
        'holdSeconds': 'Hold Seconds',
        'inQueueSeconds': 'In Queue Seconds',
        'isAnalytics Processed': 'Is Analytics Processed',
        'isLogged': 'Is Logged',
        'isOutbound': 'Is Outbound',
        'isRefused': 'Is Refused',
        'isShortAbandon': 'Is Short Abandon',
        'isTakeover': 'Is Takeover',
        'lastName': 'Last Name',
        'lastUpdateTime': 'Last Update Time',
        'lowProficiency': 'Low Proficiency',
        'MasterContactId': 'Master Contact ID',
        'mediaSubTypeId': 'Media SubType ID',
        'mediaSubTypeflame': 'Media SubType Flame',
        'mediaTypeId': 'Media Type ID',
        'refuseTime': 'Refuse Time',
        'mediaTypeNane': 'Media Type Name',
        'releaseSeconds': 'Release Seconds',
        'pointOfContactid': 'Point of Contact ID',
        'pointOfContactName': 'Point of Contact Name',
        'postQueueSeconds': 'Post Queue Seconds',
        'preQueueSeconds': 'Pre Queue Seconds',
        'primaryDispositionId': 'Primary Disposition ID',
        'routing Time': 'Routing Time',
        'secondaryDispositionId': 'Secondary Disposition ID',
        'serviceLevelFlag': 'Service Level Flag',
        'skillid': 'Skill ID',
        'skillName': 'Skill Name',
        'transferIndicatorId': 'Transfer Indicator ID',
        'transfer': 'Transfer',
        'IndicatorName': 'Indicator Name'
    }
    
    dashboard_df = df.rename(columns=col_mapping)
    
    ordered_dashboard_columns = [
        "Contact Start Date", "Processed Date", "Callback Time", "Last Update Time",
        "Date AC Warehoused", "Date Contact Warehoused", "Contact ID", "Master Contact ID",
        "Campaign ID", "Campaign Name", "Agent ID", "First Name", "Last Name",
        "From Address", "Media Type ID", "Media Type Name", "Media SubType ID", "Media SubType Flame",
        "Pre Queue Seconds", "In Queue Seconds", "Post Queue Seconds", "Abandon Seconds",
        "ACW Seconds", "Agent Seconds", "Conference Seconds", "Hold Count", "Hold Seconds",
        "Release Seconds", "Refuse Time", "Routing Time", "End Reason", "Disposition Notes",
        "Primary Disposition ID", "Secondary Disposition ID", "Service Level Flag",
        "Abandoned", "Is Analytics Processed", "Analytics", "Is Logged", "Is Outbound",
        "Is Refused", "Is Short Abandon", "Is Takeover", "High Proficiency", "Low Proficiency",
        "Point of Contact ID", "Point of Contact Name", "Skill ID", "Skill Name",
        "Transfer Indicator ID", "Transfer", "Indicator Name"
    ]
    available_columns = [col for col in ordered_dashboard_columns if col in dashboard_df.columns]
    dashboard_df = dashboard_df[available_columns]

    # --------- Sidebar Filter Options ---------
    st.sidebar.header("Filter Options")
    filtered_df = dashboard_df.copy()

    # 1. Filter by Contact Start Date Range
    if "Contact Start Date" in filtered_df.columns:
        filtered_df["Contact Start Date"] = pd.to_datetime(filtered_df["Contact Start Date"], errors='coerce')
        min_date = filtered_df["Contact Start Date"].min()
        max_date = filtered_df["Contact Start Date"].max()
        date_range = st.sidebar.date_input("Select Contact Start Date Range", [min_date.date(), max_date.date()])
        if len(date_range) == 2:
            start_date_filter, end_date_filter = date_range
            filtered_df = filtered_df[
                (filtered_df["Contact Start Date"].dt.date >= start_date_filter) & 
                (filtered_df["Contact Start Date"].dt.date <= end_date_filter)
            ]

    # 2. Filter by Campaign Name
    if "Campaign Name" in filtered_df.columns:
        campaigns = filtered_df["Campaign Name"].dropna().unique().tolist()
        selected_campaigns = st.sidebar.multiselect("Select Campaign(s)", options=campaigns, default=campaigns)
        filtered_df = filtered_df[filtered_df["Campaign Name"].isin(selected_campaigns)]

    # 3. Filter by Agent ID
    if "Agent ID" in filtered_df.columns:
        agents = filtered_df["Agent ID"].dropna().unique().tolist()
        selected_agents = st.sidebar.multiselect("Select Agent(s)", options=agents, default=agents)
        filtered_df = filtered_df[filtered_df["Agent ID"].isin(selected_agents)]

    # 4. Filter by End Reason
    if "End Reason" in filtered_df.columns:
        reasons = filtered_df["End Reason"].dropna().unique().tolist()
        selected_reasons = st.sidebar.multiselect("Select End Reason(s)", options=reasons, default=reasons)
        filtered_df = filtered_df[filtered_df["End Reason"].isin(selected_reasons)]

    # 5. Filter by Call Type (Inbound/Outbound)
    if "Is Outbound" in filtered_df.columns:
        call_type_mapping = {False: "Inbound", True: "Outbound", 0: "Inbound", 1: "Outbound"}
        filtered_df["Call Type"] = filtered_df["Is Outbound"].map(call_type_mapping)
        selected_call_types = st.sidebar.multiselect("Select Call Type", options=filtered_df["Call Type"].unique().tolist(), 
                                                       default=filtered_df["Call Type"].unique().tolist())
        filtered_df = filtered_df[filtered_df["Call Type"].isin(selected_call_types)]
    
    # 6. Filter by Skill Name
    if "Skill Name" in filtered_df.columns:
        skills = filtered_df["Skill Name"].dropna().unique().tolist()
        selected_skills = st.sidebar.multiselect("Select Skill(s)", options=skills, default=skills)
        filtered_df = filtered_df[filtered_df["Skill Name"].isin(selected_skills)]
    
    # 7. Filter by Call Duration (Agent Seconds)
    if "Agent Seconds" in filtered_df.columns:
        filtered_df["Agent Seconds"] = pd.to_numeric(filtered_df["Agent Seconds"], errors='coerce')
        min_duration = int(filtered_df["Agent Seconds"].min())
        max_duration = int(filtered_df["Agent Seconds"].max())
        duration_range = st.sidebar.slider("Select Agent Seconds Range", min_value=min_duration, max_value=max_duration, 
                                           value=(min_duration, max_duration))
        filtered_df = filtered_df[(filtered_df["Agent Seconds"] >= duration_range[0]) & 
                                  (filtered_df["Agent Seconds"] <= duration_range[1])]

    # 8. Filter by Pre Queue Seconds
    if "Pre Queue Seconds" in filtered_df.columns:
        filtered_df["Pre Queue Seconds"] = pd.to_numeric(filtered_df["Pre Queue Seconds"], errors='coerce')
        min_pre = int(filtered_df["Pre Queue Seconds"].min())
        max_pre = int(filtered_df["Pre Queue Seconds"].max())
        pre_queue_range = st.sidebar.slider("Select Pre Queue Seconds Range", min_value=min_pre, max_value=max_pre, 
                                            value=(min_pre, max_pre))
        filtered_df = filtered_df[(filtered_df["Pre Queue Seconds"] >= pre_queue_range[0]) & 
                                  (filtered_df["Pre Queue Seconds"] <= pre_queue_range[1])]

    # 9. Filter by In Queue Seconds
    if "In Queue Seconds" in filtered_df.columns:
        filtered_df["In Queue Seconds"] = pd.to_numeric(filtered_df["In Queue Seconds"], errors='coerce')
        min_in = int(filtered_df["In Queue Seconds"].min())
        max_in = int(filtered_df["In Queue Seconds"].max())
        in_queue_range = st.sidebar.slider("Select In Queue Seconds Range", min_value=min_in, max_value=max_in, 
                                           value=(min_in, max_in))
        filtered_df = filtered_df[(filtered_df["In Queue Seconds"] >= in_queue_range[0]) & 
                                  (filtered_df["In Queue Seconds"] <= in_queue_range[1])]

    # 10. Filter by Post Queue Seconds
    if "Post Queue Seconds" in filtered_df.columns:
        filtered_df["Post Queue Seconds"] = pd.to_numeric(filtered_df["Post Queue Seconds"], errors='coerce')
        min_post = int(filtered_df["Post Queue Seconds"].min())
        max_post = int(filtered_df["Post Queue Seconds"].max())
        post_queue_range = st.sidebar.slider("Select Post Queue Seconds Range", min_value=min_post, max_value=max_post, 
                                             value=(min_post, max_post))
        filtered_df = filtered_df[(filtered_df["Post Queue Seconds"] >= post_queue_range[0]) & 
                                  (filtered_df["Post Queue Seconds"] <= post_queue_range[1])]

    # Reformat "Contact Start Date" for display (remove T and Z)
    if "Contact Start Date" in filtered_df.columns:
        filtered_df["Contact Start Date"] = filtered_df["Contact Start Date"].dt.strftime("%Y-%m-%d %H:%M:%S")
    
    st.write("### Filtered Detailed Contact Center Data")
    st.dataframe(filtered_df)

    # Extra: Download Filtered Data as CSV
    csv = filtered_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="Download Filtered Data as CSV",
        data=csv,
        file_name='filtered_contact_center_data.csv',
        mime='text/csv',
    )

    # ----------------- KPI Cards -----------------
    st.write("### Key Performance Indicators")
    kpi_metrics = generate_kpi_metrics(df)
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Total Calls", kpi_metrics["Total Calls"])
    col2.metric("Answered Calls", kpi_metrics["Answered Calls"])
    col3.metric("Abandoned Calls", kpi_metrics["Abandoned Calls"])
    col4.metric("Abandon Rate (%)", kpi_metrics["Abandon Rate (%)"])
    col5, col6, col7, col8 = st.columns(4)
    col5.metric("Avg Agent Time (sec)", kpi_metrics["Avg Agent Time (sec)"])
    col6.metric("Avg Hold Time (sec)", kpi_metrics["Avg Hold Time (sec)"])
    col7.metric("Avg Wait Time (sec)", kpi_metrics["Avg Wait Time (sec)"])
    col8.metric("Avg Call Duration (sec)", kpi_metrics["Avg Call Duration (sec)"])
    
    # ----------------- Time Series Chart -----------------
    st.write("### Calls Over Time (by Minute)")
    ts_df = generate_time_series(df)
    if not ts_df.empty:
        fig_ts = px.line(ts_df, x='minute_interval', y='Calls', 
                         title="Calls Over Time",
                         labels={"minute_interval": "Time", "Calls": "Number of Calls"})
        st.plotly_chart(fig_ts, use_container_width=True)
    else:
        st.write("Time series data not available.")
    
    # ----------------- Pie Chart: Call Disposition -----------------
    st.write("### Call Disposition Distribution")
    er_df = generate_end_reason_distribution(df)
    if not er_df.empty:
        fig_er = px.pie(er_df, names='endReason', values='Calls', 
                        title="Call Disposition Distribution")
        st.plotly_chart(fig_er, use_container_width=True)
    else:
        st.write("No call disposition data available.")
    
    # ----------------- Bar Chart: Calls by Campaign -----------------
    st.write("### Calls by Campaign")
    camp_df = generate_campaign_distribution(df)
    if not camp_df.empty:
        fig_camp = px.bar(camp_df, x='campaignName', y='Calls', 
                          title="Calls by Campaign", text='Calls')
        st.plotly_chart(fig_camp, use_container_width=True)
    else:
        st.write("No campaign data available.")
    
    # ----------------- Bar Chart: Queue Metrics Comparison -----------------
    st.write("### Queue Metrics Comparison")
    if all(col in filtered_df.columns for col in ["Pre Queue Seconds", "In Queue Seconds", "Post Queue Seconds"]):
        avg_pre = filtered_df["Pre Queue Seconds"].astype(float).mean()
        avg_in = filtered_df["In Queue Seconds"].astype(float).mean()
        avg_post = filtered_df["Post Queue Seconds"].astype(float).mean()
        queue_metrics_df = pd.DataFrame({
            "Metric": ["Pre Queue Seconds", "In Queue Seconds", "Post Queue Seconds"],
            "Average Seconds": [avg_pre, avg_in, avg_post]
        })
        fig_queue = px.bar(queue_metrics_df, x="Metric", y="Average Seconds", title="Average Queue Times")
        st.plotly_chart(fig_queue, use_container_width=True)
    else:
        st.write("Queue metrics data not available.")
    
    # ----------------- In Queue Bar Chart -----------------
    st.write("### In Queue Calls by Campaign")
    if "Campaign Name" in dashboard_df.columns and "In Queue Seconds" in dashboard_df.columns:
        # Filter records with any In Queue time and group by Campaign Name
        queue_count_df = dashboard_df[dashboard_df["In Queue Seconds"].astype(float) > 0].groupby("Campaign Name").size().reset_index(name="Call Count")
        fig_inqueue = px.bar(queue_count_df, x="Campaign Name", y="Call Count", 
                             title="Calls with In Queue Time by Campaign", labels={"Call Count": "Number of Calls"})
        st.plotly_chart(fig_inqueue, use_container_width=True)
    else:
        st.write("In Queue chart data not available.")
    
    # ----------------- Queue Details Table -----------------
    st.write("### Queue Details Table")
    # Display a table with full name, from address, campaign name, and queue times
    required_cols = ["First Name", "Last Name", "From Address", "Campaign Name", "Pre Queue Seconds", "In Queue Seconds", "Post Queue Seconds"]
    if all(col in dashboard_df.columns for col in required_cols):
        queue_df = dashboard_df[required_cols].copy()
        queue_df["Full Name"] = queue_df["First Name"].fillna('') + " " + queue_df["Last Name"].fillna('')
        queue_df = queue_df[["Full Name", "From Address", "Campaign Name", "Pre Queue Seconds", "In Queue Seconds", "Post Queue Seconds"]]
        st.dataframe(queue_df)
    else:
        st.write("Queue details data not available.")
    
    # ----------------- Extra Chart: Top 5 Agents by Call Count with Drill Down -----------------
    st.write("### Top 5 Agents by Call Count (Click a bar to drill down)")
    top_agents_df = generate_top_agents(dashboard_df)
    if not top_agents_df.empty:
        fig_agents = px.bar(top_agents_df, x='Agent ID', y='Calls', 
                            title="Top 5 Agents by Call Count", text='Calls')
        selected_agent = plotly_events(fig_agents, click_event=True)
        st.plotly_chart(fig_agents, use_container_width=True)
        if selected_agent:
            agent_id = selected_agent[0]['x']
            st.write(f"#### Drill Down: Details for Agent {agent_id}")
            agent_calls_df = dashboard_df[dashboard_df["Agent ID"] == agent_id]
            st.dataframe(agent_calls_df)
            ts_agent = generate_time_series(agent_calls_df)
            if not ts_agent.empty:
                fig_agent_ts = px.line(ts_agent, x='minute_interval', y='Calls',
                                       title=f"Calls Over Time for Agent {agent_id}",
                                       labels={"minute_interval": "Time", "Calls": "Number of Calls"})
                st.plotly_chart(fig_agent_ts, use_container_width=True)
    else:
        st.write("No agent data available.")
    
    # ----------------- Additional Summaries -----------------
    summary_df = generate_summary(df)
    st.write("### TFN-Wise Summary Data")
    st.dataframe(summary_df.style.background_gradient(cmap='viridis'))
    
    ivr_bucket_summary_df = generate_ivr_bucket_summary(df)
    st.write("### IVR Abandon Bucket Wise Data")
    st.dataframe(ivr_bucket_summary_df.style.background_gradient(cmap='plasma'))
    
else:
    st.write("No data fetched for the given time range.")
