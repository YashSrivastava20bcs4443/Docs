
import os
import requests
import pandas as pd
from datetime import datetime, timedelta, timezone
import psycopg2
from psycopg2 import SQL
import json


# API and Access Token Details
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"

# PostgreSQL connection details
DB_CONFIG = {
    "host": "172.16.130.247",
    "database": "postgres",
    "user": "postgres",
    "password": "Zxcv@1234",
}


def get_access_token():
    """Fetch access token from API."""
    try:
        response = requests.post(ACCESS_TOKEN_URL)
        response_data = response.json()
        if "access_token" in response_data:
            print("Access Token generated successfully.")
            return response_data['access_token']
        else:
            raise Exception("Failed to generate access token.")
    except Exception as e:
        print(f"Error generating access token: {e}")
        exit()


def fetch_data(start_date, end_date, auth_token):
    """Fetch data from API."""
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json",
    }
    all_data = []
    skip = 0
    top = 10000

    while True:
        params = {
            "startdate": start_date,
            "enddate": end_date,
            "top": top,
            "skip": skip,
        }
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()

        if "completedContacts" in data and data["completedContacts"]:
            all_data.extend(data["completedContacts"])
            skip += top
            if len(data["completedContacts"]) < top:
                break
        else:
            break

    print(f"Total records fetched: {len(all_data)}")
    return all_data


def save_to_csv(data, file_name):
    """Save raw data to CSV with nested structures handled."""
    # Convert any dict or list fields to JSON strings
    processed_data = []
    for record in data:
        processed_record = {
            key: json.dumps(value) if isinstance(value, (dict, list)) else value
            for key, value in record.items()
        }
        processed_data.append(processed_record)
    
    df = pd.DataFrame(processed_data)
    df.to_csv(file_name, index=False)
    print(f"Data saved to CSV: {file_name}")
    return df


def create_table_and_insert_data(df, table_name, conn):
    """Create table and insert data into PostgreSQL."""
    with conn.cursor() as cur:
        # Create table dynamically based on DataFrame columns
        columns = [
            f"{col} {'bigint' if pd.api.types.is_integer_dtype(df[col]) else 'text'}"
            for col in df.columns
        ]
        create_table_query = f"""
        CREATE TABLE IF NOT EXISTS {table_name} (
            {', '.join(columns)}
        );
        """
        cur.execute(create_table_query)

        # Insert data
        for _, row in df.iterrows():
            # Ensure all values are strings to avoid "can't adapt type" errors
            row_data = [
                json.dumps(value) if isinstance(value, (dict, list)) else value
                for value in row
            ]
            insert_query = sql.SQL(
                f"INSERT INTO {table_name} ({', '.join(df.columns)}) VALUES ({', '.join(['%s'] * len(df.columns))})"
            )
            cur.execute(insert_query, tuple(row_data))
        conn.commit()
        print(f"Data inserted into table: {table_name}")


def filter_data(df):
    """Filter data as per requirements and return a new DataFrame."""
    filtered_data = []
    unique_numbers = df["toAddr"].unique()

    for number in unique_numbers:
        subset = df[df["toAddr"] == number]
        offered = len(subset)
        answered = len(subset[subset["abandoned"] == False])
        ivr_abandon = len(
            subset[
                (subset["abandoned"] == True)
                & (subset["agentSeconds"] == 0)
                & (subset["preQueueSeconds"] > 1)
                & (subset["inQueueSeconds"] == 0)
                & (subset["endReason"] == "Contact Hung Up")
            ]
        )
        polite_disconnect = len(
            subset[
                (subset["abandoned"] == True)
                & (subset["agentSeconds"] == 0)
                & (subset["preQueueSeconds"] > 1)
                & (subset["inQueueSeconds"] == 0)
                & (subset["endReason"] == "Contact Hang Up via Script")
            ]
        )
        queue_abandon = len(
            subset[
                (subset["abandoned"] == True)
                & (subset["agentSeconds"] == 0)
                & (subset["inQueueSeconds"] > 0)
                & (subset["preQueueSeconds"] > 0)
            ]
        )

        filtered_data.append(
            {
                "Number": number,
                "Offered Calls": offered,
                "Answered": answered,
                "IVR Abandon": ivr_abandon,
                "Queue Abandon": queue_abandon,
                "Polite Disconnect": polite_disconnect,
            }
        )

    return pd.DataFrame(filtered_data)


if __name__ == "__main__":
    try:
        # Generate Access Token
        auth_token = get_access_token()

        # Set the time range for the last 2 hours
        end_date = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
        start_date = (datetime.now(timezone.utc) - timedelta(hours=2)).strftime(
            "%Y-%m-%dT%H:%M:%SZ"
        )

        # Fetch data from the API
        raw_data = fetch_data(start_date, end_date, auth_token)

        # Save raw data to CSV
        csv_file_name = "raw_data.csv"
        raw_df = save_to_csv(raw_data, csv_file_name)

        # Connect to PostgreSQL
        conn = psycopg2.connect(**DB_CONFIG)

        # Create and insert raw data into PostgreSQL
        create_table_and_insert_data(raw_df, "raw_df", conn)

        # Filter data and save to PostgreSQL
        filtered_df = filter_data(raw_df)
        create_table_and_insert_data(filtered_df, "filtered_data", conn)

        # Print column names and 5 rows of each DataFrame
        print("Raw Data Columns:", raw_df.columns)
        print("Raw Data Sample:\n", raw_df.head())
        print("Filtered Data Columns:", filtered_df.columns)
        print("Filtered Data Sample:\n", filtered_df.head())

    except Exception as e:
        print(f"Error: {e}")

    finally:
        # Delete CSV file
        if os.path.exists(csv_file_name):
            os.remove(csv_file_name)
            print(f"CSV file '{csv_file_name}' deleted.")
        else:
            print("CSV file not found for deletion.")

        if conn:
            conn.close()
