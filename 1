import requests
import json
import csv
import os
import psycopg2
from datetime import datetime, timedelta, timezone

# API and Access Token Details
API_URL = "https://api-c48.nice-incontact.com/incontactapi/services/v31.0/contacts/completed"
ACCESS_TOKEN_URL = "http://ctiintegrationapi.operations.fareportal.com.local/api/Agent/accessToken"

# Database Configuration
DB_CONFIG = {
    "host": "172.16.130.247",
    "database": "postgres",
    "user": "postgres",
    "password": "Zxcv@1234"
}

CSV_FILE = "raw_data.csv"

# Generate Access Token
def get_access_token():
    response = requests.post(ACCESS_TOKEN_URL)
    response_data = response.json()
    if "access_token" in response_data:
        print("Access Token generated successfully.")
        return response_data['access_token']
    else:
        raise Exception("Failed to generate access token.")

# Fetch data from API
def fetch_data(start_date, end_date, auth_token):
    headers = {
        "Authorization": f"Bearer {auth_token}",
        "Content-Type": "application/json"
    }
    all_data = []
    skip = 0
    top = 10000

    while True:
        params = {
            "startdate": start_date,
            "enddate": end_date,
            "top": top,
            "skip": skip
        }
        response = requests.get(API_URL, headers=headers, params=params)
        data = response.json()

        if "completedContacts" in data and data["completedContacts"]:
            all_data.extend(data["completedContacts"])
            skip += top
            if len(data["completedContacts"]) < top:
                break
        else:
            break

    print(f"Total records fetched: {len(all_data)}")
    return all_data

import csv

# Save data to a CSV file
def save_to_csv(data, file_name="data.csv"):
    if not data:
        print("No data to save.")
        return

    # Dynamically determine fieldnames from the data
    fieldnames = set()
    for record in data:
        fieldnames.update(record.keys())
    fieldnames = list(fieldnames)

    try:
        with open(file_name, mode="w", newline="", encoding="utf-8") as file:
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(data)
        print(f"Data saved successfully to {file_name}.")
    except Exception as e:
        print(f"Error saving to CSV: {e}")


# Print CSV column names and first 5 rows
def print_csv_preview():
    with open(CSV_FILE, "r") as f:
        reader = csv.reader(f)
        columns = next(reader)
        print("Columns:", columns)
        for i, row in enumerate(reader):
            print(row)
            if i == 4:  # Print first 5 rows
                break

# Load data into PostgreSQL
def load_to_postgres(table_name):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    with open(CSV_FILE, "r") as f:
        cursor.copy_expert(f"COPY {table_name} FROM STDIN WITH CSV HEADER", f)
    conn.commit()
    print(f"Data loaded into table {table_name}.")
    cursor.close()
    conn.close()

# Filter data and save to a new table
def process_and_store_data():
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()

    query = """
        CREATE TABLE IF NOT EXISTS processed_df AS
        SELECT 
            toaddress AS number,
            COUNT(*) FILTER (WHERE mediatypeid = 4 AND isoutbound = false) AS offered_calls,
            COUNT(*) FILTER (WHERE mediatypeid = 4 AND isoutbound = false AND agentseconds > 0) AS answered,
            COUNT(*) FILTER (WHERE mediatypeid = 4 AND isoutbound = false AND agentseconds = 0 AND inqueueseconds = 0 AND prequeueseconds > 1 AND endreason = 'Contact Hung Up') AS ivr_abandon,
            COUNT(*) FILTER (WHERE mediatypeid = 4 AND isoutbound = true AND agentseconds = 0 AND inqueueseconds > 0 AND prequeueseconds > 0) AS queue_abandon,
            COUNT(*) FILTER (WHERE mediatypeid = 4 AND isoutbound = false AND agentseconds = 0 AND inqueueseconds = 0 AND prequeueseconds > 1 AND endreason = 'Contact Hang Up via Script') AS polite_disconnect
        FROM raw_df
        GROUP BY toaddress;
    """
    cursor.execute(query)
    conn.commit()
    print("Filtered data processed and saved.")
    cursor.close()
    conn.close()

# Main Execution
if __name__ == "__main__":
    auth_token = get_access_token()

    # Fetch data for the last 2 hours
    end_date = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')
    start_date = (datetime.now(timezone.utc) - timedelta(hours=2)).strftime('%Y-%m-%dT%H:%M:%SZ')
    data = fetch_data(start_date, end_date, auth_token)

    if data:
        save_to_csv(data)
        print_csv_preview()
        load_to_postgres("raw_df")
        process_and_store_data()
        os.remove(CSV_FILE)
        print(f"{CSV_FILE} deleted.")
    else:
        print("No data fetched.")
